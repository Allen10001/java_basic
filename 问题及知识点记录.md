# java基础专题

## Commons CLI 入门及代码简单分析

https://cloud.tencent.com/developer/article/1622149

>## 入门
>
>commons-cli 中把解释参数分为三种状态，分别是**定义、解释和询问交互**。
>
>### 定义
>
>在定义这一部分，最重要的类是`Option`，Option类中定义了一个基本的选项，例如`-t xxx` ，是否为必选项，该命令的解释等等。
>
>### 解析
>
>接下来就是`CommandLineParser`接口，**在1.3.1版本中取消了Parser抽象类，`GnuParser`、`BasicParser`、`PosixParser`类，取而代之的是`DefaultParser`类。DefaultParser类提供了对Options实例的解析，即对入参命令和Options实例之间对应关系的解析，返回的类是CommandLine。如果入参命令与Options实例对应不上就会抛出解析异常。**
>
>DefaultParser 类解析方法最基本的方法是handleToken(String token)，token是每一个入参字符串。这个方法会在解析错误的时候抛出解析异常。
>
>### 查询交互
>
>`CommandLine`可以对入参命令进行判断解析，例如可以查询是否存在某个选项，以及获取这个选项的值。



## org.aopalliance.intercept  ？？  

面向切面编程的接口标准。



## @RefreshScope 支持动态刷新 ？？



## java.lang.reflect.Type  的作用？ 

###  【Java】java.lang.reflect.Type详解

https://blog.csdn.net/u013718730/article/details/106165426/

>
>
>

## Java Reflections框架，类扫描工具

https://www.jianshu.com/p/49199793aff3

>Reflection框架可以：
>
>- 获取某个类型的全部子类
>- 只要类型、构造器、方法，字段上带有特定注解，便能获取带有这个注解的全部信息（类型、构造器、方法，字段）
>- 获取所有能匹配某个正则表达式的资源
>- 获取所有带有特定签名的方法，包括参数，参数注解，返回类型
>- 获取所有方法的名字
>- 获取代码里所有字段、方法名、构造器的使用
>
>

## Java多线程问题--方法await()和awaitUninterruptibly()的用法和区别

https://blog.csdn.net/XIANZHIXIANZHIXIAN/article/details/86633966

>使用了condition.await()的线程被中断后报错，使用了condition.awatUninterruptibly()的线程被中断后不报错。

## spring-boot-devtools: 免费的热部署工具

https://blog.csdn.net/fly910905/article/details/115550175

>**spring-boot-devtools**
>是一个为开发者服务的一个模块，其中最重要的功能就是自动将应用代码更改到最新的App上面去，即在我们改变了一些代码或者配置文件的时候，应用可以自动重启，这在我们开发的时候，非常有用。
>
>**重新启动 vs 重新加载**
>Spring Boot 提供的重启技术通过使用两个类加载器来工作。
>
>**不改变的类（例如来自第三方jar的类）被加载到base classloader中。**
>
>**我们正在开发的类会加载到restart classloader中。当应用程序重新启动时，restart classloader 将被丢弃并创建一个新类。这种方法意味着应用程序重启通常比"cold starts"快得多，因为基类加载器已经可用并且已经被填充。**
>

## [Java 受检异常与lambda表达式](https://geek-docs.com/java/java-examples/java-client-and-lambda-expressions.html)

>### Java 受检异常与lambda表达式 问题描述
>
>存在一个抛出受检异常的 lambda 表达式，且所实现的函数式接口中的抽象方法并未声明该异常。
>
>### Java 受检异常与lambda表达式 解决方案
>
>为 lambda 表达式添加一个 try/catch 代码块，或委托给某个提取的方法进行处理。
>
>### Java 受检异常与lambda表达式 具体实例
>
>lambda 表达式实际上属于**函数式接口中单一抽象方法的实现，因此只能抛出在抽象方法签名中声明的受检异常。**
>

## Java 子类和父类同名属性

https://blog.csdn.net/Komatsu_1137/article/details/122597789?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-122597789-blog-89155433.pc_relevant_multi_platform_whitelistv3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-122597789-blog-89155433.pc_relevant_multi_platform_whitelistv3&utm_relevant_index=2

>![image-20221124223656786](问题及知识点记录.assets/image-20221124223656786.png)
>
>### 总结
>
>若子类有一个属性，和父类的某个属性同名，则该属性和父类的同名属性是完全独立的，想要调用父类的属性要用super。
>
>若子类的属性是由父类继承得到的，则会获取和改变父类属性的值。

## URL和URI的区别

https://maizitoday.github.io/post/url%E5%92%8Curi%E7%9A%84%E5%8C%BA%E5%88%AB/



## 高性能 Java 计算服务的性能调优实战

https://mp.weixin.qq.com/mp/profile_ext?action=home&__biz=MzI4NjY4MTU5Nw==&scene=124#wechat_redirect



## 反射

### 反射创建对象和直接 new 创建对象的区别？？

* new 只能用于编译期就能确定的类型, 而反射可以在运行时才确定类型并创建其对象.

  反射代替new就是为了接口和实现分离.

* 实际应用：

```java
反射可以不用import就生成对象一般会配合接口使用如果不用反射，interface myobj=new classimpl（）这样接口和实现类都要import进来这样的话，如果实现类发生变动，需要重新编译，那这段代码也需要重新编译如果用反射的话，实现类可以不用import进来也能生成一个满足接口的对象出来这样当实现类改动的时候，这段代码可以不用重新编译，这样就实现了解偶 decoupling 的目的.
链接：https://www.zhihu.com/question/340517449/answer/788991501
```

### new对象不行吗？为什么要用反射？

https://zhuanlan.zhihu.com/p/461723456

>![image-20220531162516853](问题及知识点记录.assets/image-20220531162516853.png)
>
>1. 首先程序启动，Person.java文件编译成Person.class文件；
>2. 程序执行到new Person()，开辟内存空间
>3. 类加载器将Person.class加载到JVM内存中；
>4. 将Person.class加载到JVM的同时也会将person对象，以及Person类的Class对象加载到JVM内存中。
>
>不知道大家看完上述流程会不会出现如下问题：
>
>- 没有new对象，启动会不会加载该类？ 不会
>- new了对象，不调用，启动会不会加载该类？不会，调用了会被加载
>- 类真的是只会被加载一次吗？是的
>
>只有被系统使用的类才会被JVM加载，且每个类只会被加载一次，类加载后会生成一个Class对象，该Class对象中包含这个类的所有信息！
>
>通过类加载的流程我们知道，类被加载后会生成一个对前类的Class对象，该Class对象包含了这个类的所有信息，而**反射就是通过读取这个Class对象，反向获取类的相关信息，并对其进行相关操作。**
>
>## 反射缺点
>
>反射很强大，但不应该乱用，因为使用反射会给我们带来一些困扰，比如：
>
>- 性能开销：**反射涉及动态解析类型，因此无法执行某些Java虚拟机的优化**，**应该避免在性能敏感功能中使用反射**
>- **安全限制**：反射需要在安全管理器下运行时可能不存在的运行时权限。对于必须在受限安全上下文中运行的代码（例如在 Applet 中），这是一个重要的考虑因素。
>- 内部暴露：**反射允许代码执行在非反射代码中非法的操作，例如访问private字段和方法，因此使用反射可能会导致意想不到的副作用，这可能会导致代码功能失调并可能破坏可移植性。**反射代码打破了抽象，因此可能会随着平台的升级而改变行为。

## DigestInputStream ??

>
>
>

## java.nio.ByteBuffer  ??

### [java.nio.ByteBuffer用法小结](https://blog.csdn.net/mrliuzhao/article/details/89453082)

>



### [java线程阻塞LockSupport.park()和Thread.sleep()、Object.wait()的区别](http://bcxw.net/article/755.html)

>**4.park和sleep、wait的区别**
>
>4.1park、unpark方法和wait、notify()方法有一些相似的地方。都是休眠，然后唤醒。但是wait、notify方法有一个不好的地方，就是我们在编程的时候必须能保证wait方法比notify方法先执行。如果notify方法比wait方法晚执行的话，就会导致因wait方法进入休眠的线程接收不到唤醒通知的问题。而park、unpark则不会有这个问题，我们可以先调用unpark方法释放一个许可证，这样后面线程调用park方法时，发现已经许可证了，就可以直接获取许可证而不用进入休眠状态了。

### [java AQS的实现原理（大部分同步类都依赖AQS实现）](https://www.jianshu.com/p/279baac48960)

>**2.1 Sync.nonfairTryAcquire**
>
>1.该方法会首先判断当前状态，**如果c==0说明没有线程正在竞争该锁，如果不c !=0 说明有线程正拥有了该锁。**
> 2.**如果发现c==0，则通过CAS设置该状态值为acquires,acquires的初始调用值为1，每次线程重入该锁都会+1，每次unlock都会-1，但为0时释放锁。**如果CAS设置成功，则可以预计其他任何线程调用CAS都不会再成功，也就认为当前线程得到了该锁，也作为Running线程，**很显然这个Running线程并未进入等待队列。**
> 3.**如果c !=0 但发现自己已经拥有锁，**只是简单地++acquires，并修改status值，但因为没有竞争，所以通过setStatus修改，而非 CAS，**也就是说这段代码实现了偏向锁的功能，并且实现的非常漂亮。**
>
>
>
>

------



### [java中的float和double的精度问题](https://www.cnblogs.com/vineleven/p/8267005.html)

>**1、背景知识** 
>在java中没有细讲，只是讲了float占32位（bit），double占 64位。 
>对于计算机来说，用位数表示是合适的。但有人喜欢用字节(byte)表示。一个字节占8位。 
>1 byte = 8 bit. 
>所以float占4个字节，double占8个字节。 
>不过我还是喜欢用位数表示。这样更直接，也更容易理解计算机是怎么存储这些类型的。
>
>**3、下面切入正题** 
>===================== 
>在c++中单精度float类型与双精度double类型的问题 
>
>【"单精度用float表示，在计算机中使用4位字节（32位bit）来表示，具有7位有效数字"】 
>
>float类型存储的时候1个bit是符号位，8个bit是指数位，剩下的23个bit是有效数字位。 
>2的23次方是8388608，即7位有效数字，精度（10进制）。 
>
>一个单精度的浮点数在内存当中占用了32个bit位，按照浮点数的表示标准，最高位表示符号，这32位一部分用来表示阶码，一部分用来表示小数部分。 
>按照这个表示方法转化成10进制之后，它能表示的最高精度是7位有效数字。 
>
>比如 
>float a=3.14159;a在内存中实际上表示为0.314159乘以10的1次方（0是符号位），而分配给a的存储单元就分为两部分，一部分存0.314159，一部分存指数1，而且也都是转化为2进制来存。 
>
>================== 
>float ，1位符号位， 8位指数位，23位尾数位 
>double，1位符号位，11位指数位，52位尾数位 
>
>float尾数位23位，2^23=8.3E6，7位，所以不同的编译器规定不同，有些是7位，有些8位 
>double尾数52位，2^52=4.5E15，15位，所以double的有效位数是15位 .

### [对 AtomicReference 的理解和使用](http://ckjava.com/2020/05/08/Java-AtomicReference-understand-practice/)

>## 2 方法列表
>
>1. public final V get() 以非原子的方式 返回当前值
>2. public final void set(V newValue) 以非原子的方式 直接将值设置为预期值
>3. public final void lazySet(V newValue) 以原子的方式 将值设置为预期值
>4. public final boolean compareAndSet(V expect, V update) 以原子的方式 只有在当前值等于预期值的时候才会将值更新，返回是否更新成功
>5. public final boolean weakCompareAndSet(V expect, V update) 以原子的方式 只有在当前值等于预期值的时候才会将值更新，返回是否更新成功
>6. public final V getAndSet(V newValue) 以原子的方式修改后返回旧值
>7. public final V getAndUpdate(UnaryOperator updateFunction) 以原子的方式 修改后返回旧值
>8. public final V updateAndGet(UnaryOperator updateFunction) 以原子的方式 修改后返回新值
>9. public final V getAndAccumulate(V x, BinaryOperator accumulatorFunction) 以原子的方式 修改指定值后返回旧值
>10. public final V accumulateAndGet(V x, BinaryOperator accumulatorFunction) 以原子的方式 修改指定值后返回新值
>
>## 3 构造函数
>
>1. `public AtomicReference()`
>2. `public AtomicReference(V initialValue)`

### [高并发编程之ConcurrentLinkedDeque讲解]( https://blog.csdn.net/weixin_42146366/article/details/88012792)

>四、总结
>①、基于链接节点的无界并发deque 。 并发插入，删除和访问操作可以跨多个线程安全执行。 一个 ConcurrentLinkedDeque是许多线程将共享对公共集合的访问的适当选择。 像大多数其他并发集合实现一样，此类不允许使用null元素， ConcurrentLinkedDeque是一个双向链表 。
>
>②、ConcurrentLinkedDeque使用了自旋+CAS的非阻塞算法来保证线程并发访问时的数据一致性。由于队列本身是一种双链表结构，所以虽然算法看起来很简单，但其实需要考虑各种并发的情况，实现复杂度较高，并且ConcurrentLinkedDeque不具备实时的数据一致性，实际运用中，如果需要一种线程安全的栈结构，可以使用ConcurrentLinkedDeque。
>
>③、关于ConcurrentLinkedDeque还有以下需要注意的几点：
>
>1、ConcurrentLinkedDeque的迭代器是弱一致性的，这在并发容器中是比较普遍的现象，主要是指在一个线程在遍历队列结点而另一个线程尝试对某个队列结点进行修改的话不会抛出ConcurrentModificationException，这也就造成在遍历某个尚未被修改的结点时，在next方法返回时可以看到该结点的修改，但在遍历后再对该结点修改时就看不到这种变化。
>2、size方法需要遍历链表，所以在并发情况下，其结果不一定是准确的，只能供参考。
>————————————————
>版权声明：本文为CSDN博主「住手丶让我来」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
>原文链接：https://blog.csdn.net/weixin_42146366/article/details/88012792

### 两个不同的类加载加载同一个类时可能导致的问题？？

1. https://stackoverflow.com/questions/29504180/slf4j-error-class-loader-have-different-class-objects-for-the-type

>In Java, **the class signature is composed of the class full qualified name and the classloader that loaded the class. If a class is loaded two times from two different classloaders (same hierarchy), there will be two different classes for the JVM. Trying to point a object reference of one class to a variable of the other will trhow a ClassCastException. **

2. java多类加载器类冲突案例分析

   http://www.zyiz.net/tech/detail-151948.html

>众所周知，jvm类加载机制采用双亲委派机制。但在有些框架中，常常为了提供某种形式的“隔离和沙盒”，自定义一种称为`ChildFirst`的了类加载器，简单的说就是破坏了双亲委派，由自定义子类加载器优先加载类，而不是先委派给父加载器。由于同一个类可以在不同的类加载器中分别加载，使用`ChildFirst`机制，可以让类加载器形成一个“沙盒”，在程序中同时运行两个相同但不同版本的类。

3. [Java LinkageError:loader constraint violation 异常分析与解决](https://bigzuo.github.io/2017/03/19/java-LinkageError-loader-constraint-violation-error/)     

>当解析`"org.slf4j.impl.StaticLoggerBinder.getLoggerFactory()Lorg/slf4j/ILoggerFactory;"`方法时，类`org/slf4j/LoggerFactory`的加载器是`instance of org/apache/catalina/loader/WebappClassLoader`，但是类`org/slf4j/impl/StaticLoggerBinder`的类加载器是`instance of org/apache/catalina/loader/StandardClassLoader`，因此分别被两个类加载器加载的类`org/slf4j/LoggerFactory`发生交互，所以JVM抛出“**LinkageError**”异常。
>
>读到这里，大家就应该可以很明显发现问题所在：
>
>- Tomcat启动时，**Common**加载器会加载`$CATALINA_HOME/lib`和`$CATALINA_BASE/lib`目录下的**slf4j-api-1.7.7.jar** jar包中的类，其中包括`org/slf4j/LoggerFactory`类。日志中显示的类加载器是`instance of org/apache/catalina/loader/StandardClassLoader`，因为`CommonLoader`是`StandardClassLoader`的子类。
>- **WebappX**加载器会加载`/WEB-INF/lib`目录下所有的jar包中的类和额外的类，也包括**slf4j-api-1.7.7.jar** jar包中的`org/slf4j/LoggerFactory`类。日志显示的类加载器是`WebappClassLoader`。
>- 当应用程序在解析`"org.slf4j.impl.StaticLoggerBinder`类的`getLoggerFactory()`方法时，发现同一个类有两个不同的类加载器，类加载器冲突，所以抛出`java.lang.LinkageError`异常。

4. [探讨ClassLoader引发的 java.lang.LinkageError](https://blog.csdn.net/helowken2/article/details/87927831)  全面  ？？？

   >问题探讨
   >先好好解读一下异常信息：
   >
   >1. 存在2个ClassLoader：WebAppClassLoader 和 URLClassLoade
   >2. 由WebAppClassLoader加载的LoggerFactory，在调用自身getILoggerFactory()方法时，需要解析调用StaticLoggerBinder.getLoggerFactory()方法
   >3. StaticLoggerBinder由URLClassLoader加载
   >4. LoggerFactory.getILoggerFactory()方法，返回类型是ILoggerFactory，由WebAppClassLoader加载
   >  StaticLoggerBinder.getLoggerFactory()方法，返回类型为ILoggerFactory，由URLClassLoader加载
   >5. **JVM认为这2个ILoggerFactory虽然源于同一个类，但是由不同的ClassLoader加载，所以它们拥有不同的签名，不能被视作同一类型，于是报错**
   >
   >**LoggerFactory**的源码：
   >
   >```java
   >    public static ILoggerFactory getILoggerFactory() {
   >		...
   >        switch (INITIALIZATION_STATE) {
   >        case SUCCESSFUL_INITIALIZATION:
   >            return StaticLoggerBinder.getSingleton().getLoggerFactory(); // 在这里调用的
   >		...
   >    }
   >```
   >
   >jetty 在加载web应用的时候，每个应用都使用一个独立的 WebAppClassLoader，它继承了URLClassLoader，应用启动时，会把自己lib目录下的所有jar包和classes目录添加到它的资源列表中(URLClassPath)，查看它的 loadClass()方法，可以知道它会优先从自己的资源列表中查找class：
   >
   >```java
   >    @Override
   >    protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {
   >        synchronized (getClassLoadingLock(name)) {
   >            ClassNotFoundException ex = null;
   >            Class<?> parent_class = null;
   >            Class<?> webapp_class = null;
   >
   >			// 如果已经加载过，则直接返回
   >            webapp_class = findLoadedClass(name);
   >            if (webapp_class != null) {
   >                if (LOG.isDebugEnabled())
   >                    LOG.debug("found webapp loaded {}", webapp_class);
   >                return webapp_class;
   >            }
   >
   >			// 看是否优先使用parent来查找
   >            if (_context.isParentLoaderPriority()) {
   >           		// 一般都不会走这个分支，因为web应用应该优先使用自己的class和jar
   >                ... 
   >            } else {
   >                // 从这里可以看出，应用会优先使用自己的资源来查找class
   >                // loadAsResource方法会调用URLClassLoader的findResource来查找class的URL
   >                webapp_class = loadAsResource(name, true); 
   >
   >                if (webapp_class != null) {
   >                    return webapp_class;
   >                }
   >				// 往下是使用parent来加载
   >				...
   >            }
   >        }
   >    }
   >
   >```
   >
   >结论：
   >一旦出现LinkageError：
   >
   >系统存在多个ClassLoader，某些类都被它们加载过
   >它们之间存在代理关系
   >它们在执行方法调用的时候，出现了交集
   >解决方法：
   >
   >1. 根据错误信息，找出冲突的类所在的URL（jar包，目录，远程资源）
   >2. 看哪些ClassLoader的资源列表引入了这些URL
   >3. 尽量简化为只在其中一个ClassLoader进行加载，即优先通过代理加载
   >或者让各个ClassLoader都拥有完整的资源列表，即不进行代理加载

### [通俗易懂的双亲委派机制](https://blog.csdn.net/codeyanbao/article/details/82875064)

>你得先知道
>在介绍双亲委派机制的时候，不得不提ClassLoader（类加载器）。说ClassLoader之前，我们得先了解下Java的基本知识。  
>Java是运行在Java的虚拟机(JVM)中的，但是它是如何运行在JVM中了呢？我们在IDE中编写的Java源代码被编译器编译成.class的字节码文件。然后由我们得ClassLoader负责将这些class文件给加载到JVM中去执行。  
>
>JVM中提供了三层的ClassLoader：
>
>Bootstrap classLoader:主要负责加载核心的类库(java.lang.*等)，构造ExtClassLoader和APPClassLoader。
>
>ExtClassLoader：主要负责加载jre/lib/ext目录下的一些扩展的jar。
>
>AppClassLoader：主要负责加载应用程序的主函数类
>
>那如果有一个我们写的Hello.java编译成的Hello.class文件，它是如何被加载到JVM中的呢？别着急，请继续往下看。
>
>### 双亲委派机制
>
>我打开了我的AndroidStudio，搜索了下“ClassLoader”,然后打开“java.lang”包下的**ClassLoader**类。然后将代码翻到**loadClass**方法：
>
>```java
>public Class<?> loadClass(String name) throws ClassNotFoundException {
>   return loadClass(name, false);
>}
>//              -----??-----
>protected Class<?> loadClass(String name, boolean resolve)
>   throws ClassNotFoundException
>{
>       // 首先，检查是否已经被类加载器加载过
>       Class<?> c = findLoadedClass(name);
>       if (c == null) {
>           try {
>               // 存在父加载器，递归的交由父加载器
>               if (parent != null) {
>                   c = parent.loadClass(name, false);
>               } else {
>                   // 直到最上面的Bootstrap类加载器
>                   c = findBootstrapClassOrNull(name);
>               }
>           } catch (ClassNotFoundException e) {
>               // ClassNotFoundException thrown if class not found
>               // from the non-null parent class loader
>           }
>
>           if (c == null) {
>               // If still not found, then invoke findClass in order
>               // to find the class.
>               c = findClass(name);
>           }
>       }
>       return c;
>}
>```
>
>其实这段代码已经很好的解释了双亲委派机制，为了大家更容易理解，我做了一张图来描述一下上面这段代码的流程： 
>
>![image-20211021225747116](fj问题及知识点记录.assets/image-20211021225747116.png)
>
>从上图中我们就更容易理解了，当一个Hello.class这样的文件要被加载时。不考虑我们自定义类加载器，首先会在AppClassLoader中检查是否加载过，如果有那就无需再加载了。如果没有，那么会拿到父加载器，然后调用父加载器的loadClass方法。父类中同理也会先检查自己是否已经加载过，如果没有再往上。注意这个类似递归的过程，直到到达Bootstrap classLoader之前，都是在检查是否加载过，并不会选择自己去加载。直到BootstrapClassLoader，已经没有父加载器了，这时候开始考虑自己是否能加载了，如果自己无法加载，会下沉到子加载器去加载，一直到最底层，如果没有任何加载器能加载，就会抛出 ClassNotFoundException。那么有人就有下面这种疑问了？
>
>为什么要设计这种机制
>这种设计有个好处是，如果有人想替换系统级别的类：String.java。篡改它的实现，在这种机制下这些系统的类已经被Bootstrap classLoader加载过了（为什么？因为当一个类需要加载的时候，最先去尝试加载的就是BootstrapClassLoader），所以其他类加载器并没有机会再去加载，从一定程度上防止了危险代码的植入。
>
>总结了一张脑图如下：
>![img](fj问题及知识点记录.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvZGV5YW5iYW8=,size_16,color_FFFFFF,t_70.png)



## [JavaGuide ms 突击版](https://snailclimb.gitee.io/javaguide-interview/#/?id=javaguide面试突击版)

## 妙用Java 8中的 Function接口 消灭if...else...

>### Function 函数式接口
>
>使用注解`@FunctionalInterface`标识，并且只包含一个抽象方法的接口是函数式接口。函数式接口主要分为Supplier供给型函数、Consumer消费型函数、Runnable无参无返回型函数和Function有参有返回型函数。
>
>#### Supplier供给型函数
>
>Supplier的表现形式为不接受参数、只返回数据.
>
>#### Consumer消费型函数
>
>Consumer消费型函数和Supplier刚好相反。Consumer接收一个参数，没有返回值.
>
>#### Runnable无参无返回型函数
>
>Runnable的表现形式为即没有参数也没有返回值.
>
>**Function有参有返回型函数**
>
>Function函数的表现形式为接收一个参数，并返回一个值。`Supplier`、`Consumer`和`Runnable`可以看作Function的一种特殊表现形式。

## [javaagent使用指南](https://www.cnblogs.com/rickiyang/p/11368932.html)  看不明白???

>#### JVM启动前静态Instrument[#](https://www.cnblogs.com/rickiyang/p/11368932.html#468667690)
>
>Javaagent 是什么？
>
>Javaagent是java命令的一个参数。参数 javaagent 可以用于指定一个 jar 包，并且对该 java 包有2个要求：
>
>1. 这个 jar 包的 MANIFEST.MF 文件必须指定 Premain-Class 项。
>2. Premain-Class 指定的那个类必须实现 premain() 方法。
>
>premain 方法，从字面上理解，就是运行在 main 函数之前的的类。当Java 虚拟机启动时，在执行 main 函数之前，JVM 会先运行`-javaagent`所指定 jar 包内 Premain-Class 这个类的 premain 方法 。
>
>##### 运行时加载 instrument agent 过程：
>
>通过 JVM 的attach机制来请求目标 JVM 加载对应的agent，过程大致如下：
>
>1. 创建并初始化JPLISAgent；
>2. 解析 javaagent 里 MANIFEST.MF 里的参数；
>3. 创建 InstrumentationImpl 对象；
>4. 监听 ClassFileLoadHook 事件；
>5. 调用 InstrumentationImpl 的`loadClassAndCallAgentmain`方法，在这个方法里会去调用javaagent里 MANIFEST.MF 里指定的`Agent-Class`类的`agentmain`方法。
>
>#### Instrumentation的局限性[#](https://www.cnblogs.com/rickiyang/p/11368932.html#2512116431)
>
>大多数情况下，我们使用Instrumentation都是使用其**字节码插桩的功能，或者笼统说就是类重定义(Class Redefine)的功能**，但是有以下的局限性：
>
>1. premain和agentmain两种方式修改字节码的时机都是类文件加载之后，也就是说必须要带有Class类型的参数，不能通过字节码文件和自定义的类名重新定义一个本来不存在的类。
>
>2. 类的字节码修改称为类转换(Class Transform)，类转换其实最终都回归到类重定义Instrumentation#redefineClasses()方法，此方法有以下限制：
>
>   1. 新类和老类的父类必须相同；
>   2. 新类和老类实现的接口数也要相同，并且是相同的接口；
>   3. 新类和老类访问符必须一致。 新类和老类字段数和字段名要一致；
>   4. 新类和老类新增或删除的方法必须是private static/final修饰的；
>   5. 可以修改方法体。
>
>   ## 和类加载器比较
>
>   类加载器也可以实现运行时修改代码。但是对代码的侵入性很高。使用 java agent 能让修改字节码这个动作化于无形，对业务透明，减少侵入性。

## [java Process类详解！](https://zhuanlan.zhihu.com/p/44957705)

>java.lang
>类 Process
>java.lang.Object
>
>**java.lang.Process**
>
>public abstract class **Process**extends Object
>
>**`ProcessBuilder.start()` 和 `Runtime.exec` 方法创建一个本机进程，并返回 `Process` 子类的一个实例，该实例可用来控制进程并获得相关信息。`Process` 类提供了执行从进程输入、执行输出到进程、等待进程完成、检查进程的退出状态以及销毁（杀掉）进程的方法。**
>创建进程的方法可能无法针对某些本机平台上的特定进程很好地工作，比如，本机窗口进程，守护进程，Microsoft Windows 上的 Win16/DOS 进程，或者 shell 脚本。创建的子进程没有自己的终端或控制台。**它的所有标准 io（即 stdin、stdout 和 stderr）操作都将通过三个流 (`getOutputStream()`、`getInputStream()` 和 `getErrorStream()`) 重定向到父进程。**父进程使用这些流来提供到子进程的输入和获得从子进程的输出。因为有些本机平台仅针对标准输入和输出流提供有限的缓冲区大小，如果读写子进程的输出流或输入流迅速出现失败，则可能导致子进程阻塞，甚至产生死锁。
>当没有 `Process` 对象的更多引用时，不是删掉子进程，而是继续异步执行子进程。
>对于带有 `Process` 对象的 Java 进程，没有必要异步或并发执行由 `Process` 对象表示的进程。
>
>当`ProcessBuilder.start()` 和 `Runtime.exec` 方法执行之后都会返回一个Process类的实例，它不代表上述方法创建的进程，但是可以用来操纵该进程。那么既然可以操纵进程，那肯定要调用方法，如下：
>
>![img](fj问题及知识点记录.assets/v2-b7a769f54bc297652cb476756373eee3_720w.jpg)

## java 内部类

1.匿名内部类、静态内部类 的用法。
内部类的好处：
解决 java 只能支持单继承的问题，内部类的唯一好处就是可以方便的访问外部类的私有属性。
为什么用匿名内部类？
如果接口实现类只使用一次，那么还有必要单独定义一个子类B吗？很显然是没有必要的，所以此时就可以使用匿名内部类完成，匿名内部类的好处是使代码更加简洁，紧凑。

### [java内部类有什么作用？](https://www.zhihu.com/question/26954130)

>作者：BWH.Steven
>链接：https://www.zhihu.com/question/26954130/answer/708467570
>来源：知乎
>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
>
>
>
>## **内部类**
>
>### **(一) 概述**
>
>把类定义在另一个类的内部，该类就被称为内部类。
>
>举例：把类Inner定义在类Outer中，类Inner就被称为内部类。
>
>```java
>  class Outer {
>      class Inner {
>      }
>  }
>```
>
>### **(二) 内部类的访问规则**
>
>​	A:可以直接访问外部类的成员，包括私有
>
>​	B:外部类要想访问内部类成员，必须创建对象
>
>### **(三) 内部类的分类**
>
>​	A：成员内部类
>
>​	B：局部内部类
>
>​	C：静态内部类
>
>​	D：匿名内部类
>
>### **(1) 成员内部类**
>
>> 成员内部类——就是位于外部类成员位置的类
>> 特点：**可以使用外部类中所有的成员变量和成员方法（包括private的）**
>
>### **A：格式：**
>
>```java
>  class Outer {
>      private int age = 20;
>      //成员位置
>      class Inner {
>          public void show() {
>              System.out.println(age);
>          }
>      }
>  }
>  
>  class Test {
>      public static void main(String[] ages) {
>          //成员内部类是非静态的演示
>          Outer.Inner oi = new Outer().new Inner();
>          oi.show();
>      }
>  }
>```
>
>### **B：创建对象时：**
>
>```java
>  //成员内部类不是静态的：
>  外部类名.内部类名 对象名 = new 外部类名.new 内部类名();
>  
>  //成员内部类是静态的：
>  外部类名.内部类名 对象名 = new 外部类名.内部类名();    
>```
>
>### **C：成员内部类常见修饰符：**
>
>**A：private**
>
>如果我们的内部类不想轻易被任何人访问，可以选择使用private修饰内部类，这样我们就无法通过创建对象的方法来访问，想要访问只需要在外部类中定义一个public修饰的方法，间接调用。这样做的好处就是，我们可以在这个public方法中增加一些判断语句，起到数据安全的作用。
>
>```java
>  class Outer {
>      private class Inner {
>          public void show() {
>              System.out.println(“密码备份文件”);
>          }
>      }
>      
>      public void method() {
>          if(你是管理员){
>              Inner i = new Inner();
>              i.show();
>          }else {
>              System.out.println(“你没有权限访问”);
>          }
>      }
>  }
>```
>
>下面我们给出一个更加规范的写法
>
>```java
>  class Outer {
>      private class Inner {
>          public void show() {
>              System.out.println(“密码备份文件”);
>          }
>      }
>      //使用getXxx()获取成员内部类，可以增加校验语句（文中省略）
>      public Inner getInner() {
>          return new Inner();
>      }
>      
>      public static void main(String[] args) {
>          Outer outer = new Outer();
>          Outer.Inner inner = outer.getInner();
>          inner.show();
>      }
>  }
>```
>
>### **B：static**
>
>这种被 static 所修饰的内部类，按位置分，属于成员内部类，但也可以称作静态内部类，也常叫做嵌套内部类。具体内容我们在下面详细讲解。
>
>**D：成员内部类经典题(填空)**
>
>请在三个println 后括号中填空使得输出25,20,18
>
>```java
>  class Outer {
>      public int age = 18;    
>      class Inner {
>          public int age = 20;    
>          public viod showAge() {
>              int age  = 25;
>              System.out.println(age);//空1
>              System.out.println(this.age);//空2
>              System.out.println(Outer.this.age);//空3
>          }
>      }
>  } 
>```
>
>### **(2) 局部内部类**
>
>> 局部内部类——就是定义在一个方法或者一个作用域里面的类
>> 特点：主要是作用域发生了变化，只能在自身所在方法和属性中被使用
>
>**A 格式：**
>
>```java
>  class Outer {
>      public void method(){
>          class Inner {
>          }
>      }
>  }
>```
>
>**B：访问时：**
>
>```java
>  //在局部位置，可以创建内部类对象，通过对象调用和内部类方法
>  class Outer {
>      private int age = 20;
>      public void method() {
>          final int age2 = 30;
>          class Inner {
>              public void show() {
>                  System.out.println(age);
>                  //从内部类中访问方法内变量age2，需要将变量声明为最终类型。
>                  System.out.println(age2);
>              }
>          }
>          
>          Inner i = new Inner();
>          i.show();
>      }
>  }
>```
>
>**C: 为什么局部内部类访问局部变量必须加final修饰呢？**
>
>因为**局部变量是随着方法的调用而调用**，**使用完毕就消失**，**而堆内存的数据并不会立即消失**。
>
>所以，堆内存还是用该变量，而该变量已经没有了。**为了让该值还存在，就加final修饰。**
>
>原因是，当我们使用final修饰变量后，堆内存直接存储的**是值**，而**不是变量名**。
>
>（即上例 age2 的位置存储着常量30 而不是 age2 这个变量名）
>
>### **(3) 静态内部类**
>
>> 我们所知道static是不能用来修饰类的,但是成员内部类可以看做外部类中的一个成员,所以可以用static修饰,这种用static修饰的内部类我们称作静态内部类,也称作嵌套内部类.
>> 特点：不能使用外部类的非static成员变量和成员方法
>
>**解释**：非静态内部类编译后会默认的保存一个指向外部类的引用，而静态类却没有。
>
>**简单理解**：
>
>即使没有外部类对象，也可以创建静态内部类对象，而外部类的非static成员必须依赖于对象的调用，静态成员则可以直接使用类调用，不必依赖于外部类的对象，所以静态内部类只能访问静态的外部属性和方法。
>
>```java
>  class Outter {
>      int age = 10;
>      static age2 = 20;
>      public Outter() {        
>      }
>       
>      static class Inner {
>          public method() {
>              System.out.println(age);//错误
>              System.out.println(age2);//正确
>          }
>      }
>  }
>  
>  public class Test {
>      public static void main(String[] args)  {
>          Outter.Inner inner = new Outter.Inner();
>          inner.method();
>      }
>  }
>```
>
>
>
>### **(4) 匿名内部类**
>
>> 一个没有名字的类，是内部类的简化写法
>
>**A 格式：**
>
>```java
>  new 类名或者接口名() {
>      重写方法();
>  }
>```
>
>本质：其实是继承该类或者实现接口的子类匿名对象
>
>这也就是下例中，可以直接使用 new Inner() {}.show(); 的原因 == **子类**对象.show();
>
>```java
>  interface Inner {
>      public abstract void show();
>  }
>  
>  class Outer {
>      public void method(){
>          new Inner() {
>              public void show() {
>                  System.out.println("HelloWorld");
>              }
>          }.show();
>      }
>  }
>  
>  class Test {
>      public static void main(String[] args)  {
>          Outer o = new Outer();
>          o.method();
>      }
>  }    
>```
>
>
>
>如果匿名内部类中有多个方法又该如何调用呢？
>
>```java
>  Inter i = new Inner() {  //多态，因为new Inner(){}代表的是接口的子类对象
>      public void show() {
>      System.out.println("HelloWorld");
>      }
>  };
>```
>
>
>
>**B：匿名内部类在开发中的使用**
>
>我们在开发的时候，会看到抽象类，或者接口作为参数。
>
>而这个时候，实际需要的是一个子类对象。
>
>如果该方法仅仅调用一次，我们就可以使用匿名内部类的格式简化。
>
>\-----------------------------------------------------------------------------
>
>2019-8-17更新补充
>
>## **使用内部类的原因**
>
>## **(一) 封装性**
>
>作为一个类的编写者，我们很显然需要对这个类的使用访问者的访问权限做出一定的限制，我们需要将一些我们不愿意让别人看到的操作隐藏起来，
>
>如果我们的内部类不想轻易被任何人访问，可以选择使用private修饰内部类，这样我们就无法通过创建对象的方法来访问，想要访问只需要在外部类中定义一个public修饰的方法，间接调用。
>
>```java
>  public interface Demo {
>      void show();
>  }
>  
>  class Outer {
>      private class test implements Demo {
>          public void show() {
>              System.out.println("密码备份文件");
>          }
>      }
>      
>      public Demo getInner() {
>          return new test();
>      }
>      
>  }
>```
>
>我们来看其测试
>
>```java
>      public static void main(String[] args) {
>          Outer outer = new Outer();
>          Demo d = outer.getInner();
>          i.show();
>      }
>  
>  //运行结果
>  密码备份文件
>```
>
>这样做的好处之一就是，我们可以在这个public方法中增加一些判断语句，起到数据安全的作用。
>
>其次呢，我们的对外可见的只是getInner()这个方法，它返回了一个Demo接口的一个实例，而我们真正的内部类的名称就被隐藏起来了
>
>## **(二) 实现多继承 **
>
>我们之前的学习知道，java是不可以实现多继承的，一次只能继承一个类，我们学习接口的时候，有提到可以用接口来实现多继承的效果，即一个接口有多个实现，但是这里也是有一点弊端的，那就是，一旦实现一个接口就必须实现里面的所有方法，有时候就会出现一些累赘，但是使用内部类可以很好的解决这些问题
>
>```java
>  public class Demo1 {
>      public String name() {
>          return "BWH_Steven";
>      }
>  }
>  
>  public class Demo2 {
>      public String email() {
>          return "xxx.@163.com";
>      }
>  }
>  
>  public class MyDemo {
>  
>      private class test1 extends Demo1 {
>          public String name() {
>              return super.name();
>          }
>      }
>  
>      private class test2 extends Demo2  {
>          public String email() {
>              return super.email();
>          }
>      }
>  
>      public String name() {
>          return new test1().name();
>      }
>  
>      public String email() {
>          return new test2().email();
>      }
>  
>      public static void main(String args[]) {
>          MyDemo md = new MyDemo();
>          System.out.println("我的姓名:" + md.name());
>          System.out.println("我的邮箱:" + md.email());
>      }
>  }
>```
>
>我们编写了两个待继承的类Demo1和Demo2，在MyDemo类中书写了两个内部类，test1和test2 两者分别继承了Demo1和Demo2类，这样MyDemo中就间接的实现了多继承
>
>## **(三) 用匿名内部类实现回调功能**
>
>我们用通俗讲解就是说在Java中，通常就是编写一个接口，然后你来实现这个接口，然后把这个接口的一个对象作以参数的形式传到另一个程序方法中， 然后通过接口调用你的方法，匿名内部类就可以很好的展现了这一种回调功能
>
>```java
>  public interface Demo {
>      void demoMethod();
>  }
>  
>  public class MyDemo{
>      public test(Demo demo){
>          System.out.println("test method");
>      }
>      
>      public static void main(String[] args) {
>          MyDemo md = new MyDemo();
>          //这里我们使用匿名内部类的方式将接口对象作为参数传递到test方法中去了
>          md.test(new Demo){
>              public void demoMethod(){
>                  System.out.println("具体实现接口")
>              }
>          }
>      }
>  }
>```
>
>## **(四) 解决继承及实现接口出现同名方法的问题**
>
>编写一个接口 Demo
>
>```java
>  public interface Demo {
>      void test();
>  }
>```
>
>编写一个类 MyDemo
>
>```java
>  public class MyDemo {
>  
>      public void test() {
>          System.out.println("父类的test方法");
>      }
>      
>  }
>```
>
>编写一个测试类
>
>```java
>  public class DemoTest extends MyDemo implements Demo {
>      public void test() {
>      }
>  }
>```
>
>这样的话我就有点懵了，这样如何区分这个方法是接口的还是继承的，所以我们使用内部类解决这个问题
>
>```java
>  public class DemoTest extends MyDemo {
>  
>  
>      private class inner implements Demo {
>          public void test() {
>              System.out.println("接口的test方法");
>          }
>      }
>      
>      public Demo getIn() {
>          return new inner();
>      }
>      
>      
>      public static void main(String[] args) {
>          //调用接口而来的test()方法
>          DemoTest dt = new DemoTest();
>          Demo d = dt.getIn();
>          d.test();
>          
>          //调用继承而来的test()方法
>          dt.test();
>      }
>  }
>  
>  //运行结果
>  接口的test方法
>  父类的test方法
>```
>
>

### [java为什么匿名内部类的参数引用时final？](https://www.zhihu.com/question/21395848)

>java为什么匿名内部类的参数引用时final？ - kenan-7的回答 - 知乎 https://www.zhihu.com/question/21395848/answer/353882210
>
>**内部类会持有外部类引用和方法中参数的引用，这个是正解。反编译class文件后，内部类的class文件的构造函数参数 中会显示传入 外部类对象（必然会加）以及方法内局部变量和形参（如果内部类有调用会加），不管是基本数据类型还是引用变量，如果重新赋值了，会导致内外指向的对象不一致，所以java就暴力的规定使用final，不能重新赋值。**
>
>final如果修饰基本数据类型，不能重新赋值.
>
>final如果修饰引用对象，不能重新赋值，但是可以修改对象本身，比如修改对象的属性。

### [Why are only final variables accessible in anonymous class?](https://stackoverflow.com/questions/4732544/why-are-only-final-variables-accessible-in-anonymous-class)



## HashMap

3.(转)为什么HashMap中链表长度超过8会转换成红黑树
https://www.cnblogs.com/rgever/p/9643872.html
15、HashMap工作原理和扩容机制
https://www.jianshu.com/p/c3633291ecda

#### [hashmap扩容时死循环问题](https://blog.csdn.net/chenyiminnanjing/article/details/82706942)

>废话不多说，大家都知道，hashmap 不能用于多线程场景中，多线程下推荐使用concurrentHashmap！
>但为什么多线程下不能使用hashmap那，主要原因就在于其的**扩容机制**。
>
>扩容时，1.7 的头插法容易导致死循环。 

## int 溢出

* [java int溢出总结](https://njucz.github.io/2017/08/16/java-int溢出总结/)

>java的int是32位有符号整数类型，其最大值是0x7fffffff,最小值则是0x80000000。即int表示的数的范围是-2147483648 ～ 2147483647之间。当int类型的运算结果超出了这个范围时则发生了溢出，而且不会有任何异常抛出。

## cas in java

* [Comparable vs Comparator in Java](https://www.geeksforgeeks.org/comparable-vs-comparator-in-java/)

>**Using Comparable Interface**
>
>A comparable object is capable of comparing itself with another object. The class itself must implements the **java.lang.Comparable** interface to compare its instances.
>
>Consider a Movie class that has members like, rating, name, year. Suppose we wish to sort a list of Movies based on year of release. We can implement the Comparable interface with the Movie class, and we override the method compareTo() of Comparable interface.
>
>**Using Comparator**
>
>Unlike Comparable, Comparator is external to the element type we are comparing. It’s a separate class. We create multiple separate classes (that implement Comparator) to compare by different members.

### 浅谈CAS以及CAS在java中应用

原文链接：https://blog.csdn.net/ln_6am/article/details/85642853
它可以解决多线程并发安全的问题，以前我们对一些多线程操作的代码都是使用synchronize关键字，来保证线程安全的问题；现在我们将cas放入到多线程环境里我们看一下它是怎么解决的，我们假设有A、B两个线程同时执行一个int值value自增的代码，并且同时获取了当前的value，我们还要假设线程B比A快了那么0.00000001s，所以B先执行，线程B执行了cas操作之后，发现当前值和预期值相符，就执行了自增操作，此时这个value = value + 1;然后A开始执行，A也执行了cas操作，但是此时value的值和它当时取到的值已经不一样了，所以此次操作失败，重新取值然后比较成功，然后将value值更新，这样两个线程进入，value值自增了两次，符合我们的预期。
CAS有没有什么不好的隐患呢？
1、首先就是经典的ABA问题
2、长时间自旋非常消耗资源

### 经典的ABA问题与解决方法
https://blog.csdn.net/qq_42576040/article/details/88240595





**在hadoop中有些 Writable 类型继承了 java.lang.Comparable，同时hadoop提供了一个优化接口是继承了 java Comparator 的 RawCompatator 接口。**，该接口允许直接比较数据流中的记录，无需把数据流反序列化为对象。

### [详解 & 0xff 的作用](https://blog.csdn.net/i6223671/article/details/88924481)

> 1. 只是为了取得低八位
> 2. 保证补码的一致性

### Java protected 关键字详解

>- 基类的 protected 成员是包内可见的，并且对子类可见；
>- 若子类与基类不在同一包中，那么在子类中，子类实例可以访问其从基类继承而来的protected方法，而不能访问基类实例的protected方法。

### [java中boolean占用几个字节](http://www.spring4all.com/article/19154)

- 因为在虚拟机规范中说了，boolean值在编译之后都使用**Java虚拟机中的int数据类型**来代替，而int是4个字节，那么boolean值就是4个字节。
- **boolean 类型数组的访问与修改共用 *byte* 类型数组的baload和 bastore指令**，因为两者共用，只有两者字节一样才能通用呀，所以byte数组中一个byte是1个字节，那么boolean数组中boolean是1个字节。
- 总结：boolean在数组情况下为1个字节，单个boolean为4个字节

### [Java transient关键字使用小记](https://www.cnblogs.com/lanxuezaipiao/p/3369962.html)

* [Java ConcurrentModificationException异常原因和解决方法](https://www.cnblogs.com/dolphin0520/p/3933551.html)

>单线程解决方法：
>
>因此，在迭代器中如果要删除元素的话，需要调用Itr类的remove方法。
>
>　　将上述代码改为下面这样就不会报错了：
>
>```java
>public class Test {
>
>    public static void main(String[] args) {  
>
>    ArrayList list = new ArrayList();   
>    list.add(2);   
>    Iterator iterator = list.iterator();   
>    while(iterator.hasNext()){ 
>    Integer integer = iterator.next();  
>    if(integer==2)    
>    iterator.remove();  //注意这个地方  
>    } 
>    }
>}
>```
>
>多线程解决方法：
>
>有可能有朋友说ArrayList是非线程安全的容器，换成Vector就没问题了，实际上换成Vector还是会出现这种错误。
>
>　　原因在于，虽然Vector的方法采用了synchronized进行了同步，但是实际上通过Iterator访问的情况下，每个线程里面返回的是不同的iterator，也即是说expectedModCount是每个线程私有。假若此时有2个线程，线程1在进行遍历，线程2在进行修改，那么很有可能导致线程2修改后导致Vector中的modCount自增了，线程2的expectedModCount也自增了，但是线程1的expectedModCount没有自增，此时线程1遍历时就会出现expectedModCount不等于modCount的情况了。
>
>　　因此一般有2种解决办法：
>
>　　1）在使用iterator迭代的时候使用synchronized或者Lock进行同步；
>
>　　2）使用并发容器CopyOnWriteArrayList代替ArrayList和Vector。

### java中的lock和synchronized

JAVA并发编程：LOCK（锁）
https://www.cnblogs.com/wuhan729/p/8601108.html

1. Lock 是个接口。
总结一下，也就是说Lock提供了比synchronized更多的功能。但是要注意以下几点：
　　1）Lock不是Java语言内置的，synchronized是Java语言的关键字，因此是内置特性。Lock是一个类，通过这个类可以实现同步访问；
　　2）Lock和synchronized有一点非常大的不同，采用synchronized不需要用户去手动释放锁，当synchronized方法或者synchronized代码块执行完之后，系统会自动让线程释放对锁的占用；而Lock则必须要用户去手动释放锁，如果没有主动释放锁，就有可能导致出现死锁现象。

 Lock 接口的几个方法的区别。

1. lockInterruptibly()
当一个线程获取了锁之后，是不会被interrupt()方法中断的。因为本身在前面的文章中讲过单独调用interrupt()方法不能中断正在运行过程中的线程，只能中断阻塞过程中的线程。
2. ReentrantLock
    　　ReentrantLock，意思是“可重入锁”，关于可重入锁的概念在下一节讲述。ReentrantLock是唯一实现了Lock接口的类，并且ReentrantLock提供了更多的方法。下面通过一些实例看具体看一下如何使用ReentrantLock。
3. ReadWriteLock
    　　ReadWriteLock也是一个接口，在它里面只定义了两个方法：
4. ReentrantReadWriteLock
    　　ReentrantReadWriteLock里面提供了很多丰富的方法，不过最主要的有两个方法：readLock()和writeLock()用来获取读锁和写锁。
        　　下面通过几个例子来看一下ReentrantReadWriteLock具体用法。

5.Lock和synchronized的选择
　　总结来说， Lock 和 synchronized 有以下几点不同：
　　1）Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；
　　2）synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；
　　3）Lock 可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；
　　4）通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。
　　5）Lock可以提高多个线程进行读操作的效率。

### 深入理解Lock的底层实现原理



### ThreadLocal

ThreadLocal作用、场景、原理         （内容较简单）

https://www.jianshu.com/p/6fc3bba12f38

Java中的ThreadLocal详解
https://www.cnblogs.com/fsmly/p/11020641.html

>4、如下图所示：每个线程内部有一个名为threadLocals的成员变量，该变量的类型为ThreadLocal.ThreadLocalMap类型（类似于一个HashMap），其中的key为当前定义的ThreadLocal变量的this引用，value为我们使用set方法设置的值。每个线程的本地变量存放在自己的本地内存变量threadLocals中，如果**当前线程一直不消亡，那么这些本地变量就会一直存在（所以可能会导致内存溢出），因此使用完毕需要将其remove掉。**
>InheritableThreadLocal
>在上面说到的ThreadLocal类是不能提供子线程访问父线程的本地变量的，而InheritableThreadLocal类则可以做到这个功能。
>
>### 2、分析ThreadLocalMap内部实现
>
>　　上面我们知道ThreadLocalMap内部实际上是一个Entry数组![img](https://img2018.cnblogs.com/blog/1368768/201906/1368768-20190614112107515-173627228.png)，我们先看看Entry的这个内部类
>
>[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)
>
>```java
> 1 /**
> 2  * 是继承自WeakReference的一个类，该类中实际存放的key是
> 3  * 指向ThreadLocal的弱引用和与之对应的value值(该value值
> 4  * 就是通过ThreadLocal的set方法传递过来的值)
> 5  * 由于是弱引用，当get方法返回null的时候意味着坑能引用
> 6  */
> 7 static class Entry extends WeakReference<ThreadLocal<?>> {
> 8     /** value就是和ThreadLocal绑定的 */
> 9     Object value;
>10 
>11     //k：ThreadLocal的引用，被传递给WeakReference的构造方法
>12     Entry(ThreadLocal<?> k, Object v) {
>13         super(k);
>14         value = v;
>15     }
>16 }
>17 //WeakReference构造方法(public class WeakReference<T> extends Reference<T> )
>18 public WeakReference(T referent) {
>19     super(referent); //referent：ThreadLocal的引用
>20 }
>21 
>22 //Reference构造方法     
>23 Reference(T referent) {
>24     this(referent, null);//referent：ThreadLocal的引用
>25 }
>26 
>27 Reference(T referent, ReferenceQueue<? super T> queue) {
>28     this.referent = referent;
>29     this.queue = (queue == null) ? ReferenceQueue.NULL : queue;
>30 }
>```
>
>　　在上面的代码中，我们可以看出，**当前ThreadLocal的引用k被传递给WeakReference的构造函数，所以ThreadLocalMap中的key为ThreadLocal的弱引用。当一个线程调用ThreadLocal的set方法设置变量的时候，当前线程的ThreadLocalMap就会存放一个记录，这个记录的key值为ThreadLocal的弱引用，value就是通过set设置的值。如果当前线程一直存在且没有调用该ThreadLocal的remove方法，如果这个时候别的地方还有对ThreadLocal的引用，那么当前线程中的ThreadLocalMap中会存在对ThreadLocal变量的引用和value对象的引用，是不会释放的，就会造成内存泄漏。**
>
>　　考虑这个ThreadLocal变量没有其他强依赖，**如果当前线程还存在**，由于线程的ThreadLocalMap里面的key是弱引用，所以当前线程的ThreadLocalMap里面的ThreadLocal变量的弱引用在gc的时候就被回收，但是对应的value还是存在的这就可能造成内存泄漏(因为这个时候ThreadLocalMap会存在key为null但是value不为null的entry项)。
>
>　　总结：**THreadLocalMap中的Entry的key使用的是ThreadLocal对象的弱引用，在没有其他地方对ThreadLoca依赖，ThreadLocalMap中的ThreadLocal对象就会被回收掉，但是对应的 value 不会被回收，这个时候Map中就可能存在key为null但是value不为null的项，这需要实际的时候使用完毕及时调用remove方法避免内存泄漏。**



### Java的ConcurrentHashMap

#### [探索 ConcurrentHashMap 高并发性的实现机制](https://developer.ibm.com/zh/articles/java-lo-concurrenthashmap/) 主要针对 jdk1.7 的实现

>**非结构性修改操作**只是更改某个 HashEntry 的 value 域的值。由于对 Volatile 变量的写入操作将与随后对这个变量的读操作进行同步。当一个写线程修改了某个 HashEntry 的 value 域后，另一个读线程读这个值域，Java 内存模型能够保证读线程读取的一定是更新后的值。所以，写线程对链表的非结构性修改能够被后续不加锁的读线程“看到”。
>
>**结构性修改**，实质上是对某个桶指向的链表做结构性修改。如果能够确保：在读线程遍历一个链表期间，写线程对这个链表所做的结构性修改不影响读线程继续正常遍历这个链表。那么读 / 写线程之间就可以安全并发访问这个 ConcurrentHashMap。
>
>结构性修改操作包括 put，remove，clear。下面我们分别分析这三个操作。
>
>clear 操作只是把 ConcurrentHashMap 中所有的桶”置空”，每个桶之前引用的链表依然存在，只是桶不再引用到这些链表（所有链表的结构并没有被修改）。正在遍历某个链表的读线程依然可以正常执行对该链表的遍历。
>
>从上面的代码清单”在 Segment 中执行具体的 put 操作”中，我们可以看出：put 操作如果需要插入一个新节点到链表中时 , 会在**链表头部插入这个新节点**。此时，链表中的原有节点的链接并没有被修改。也就是说：插入新健 / 值对到链表中的操作不会影响读线程正常遍历这个链表。
>
>下面来分析 remove 操作，先让我们来看看 remove 操作的源代码实现。
>
>##### 清单 7.remove 操作
>
>```java
>V remove(Object key, int hash, Object value) {
>       lock();         // 加锁
>       try{
>           int c = count - 1;
>           HashEntry<K,V>[] tab = table;
>           // 根据散列码找到 table 的下标值
>           int index = hash & (tab.length - 1);
>           // 找到散列码对应的那个桶
>           HashEntry<K,V> first = tab[index];
>           HashEntry<K,V> e = first;
>           while(e != null&& (e.hash != hash || !key.equals(e.key)))
>               e = e.next;
>
>           V oldValue = null;
>           if(e != null) {
>               V v = e.value;
>               if(value == null|| value.equals(v)) { // 找到要删除的节点
>                   oldValue = v;
>                   ++modCount;
>                   // 所有处于待删除节点之后的节点原样保留在链表中
>                   // 所有处于待删除节点之前的节点被克隆到新链表中
>                   HashEntry<K,V> newFirst = e.next;// 待删节点的后继结点
>                   for(HashEntry<K,V> p = first; p != e; p = p.next)
>                       newFirst = new HashEntry<K,V>(p.key, p.hash,
>                                                     newFirst, p.value);
>                   // 把桶链接到新的头结点
>                   // 新的头结点是原链表中，删除节点之前的那个节点
>                   tab[index] = newFirst;
>                   count = c;      // 写 count 变量
>               }
>           }
>           return oldValue;
>       } finally{
>           unlock();               // 解锁
>       }
>   }
>```
>
>`和 get 操作一样，首先根据散列码找到具体的链表；然后遍历这个链表找到要删除的节点；最后把待删除节点之后的所有节点原样保留在新链表中，把待删除节点之前的每个节点克隆到新链表中。下面通过图例来说明 remove 操作。` 假设写线程执行 remove 操作，要删除链表的 C 节点，另一个读线程同时正在遍历这个链表。
>
>**图 4. 执行删除之前的原链表：**
>
>![img](fj问题及知识点记录.assets/Center.jpeg)
>
>**图 5. 执行删除之后的新链表**
>
>![img](fj问题及知识点记录.assets/Center-20211025151747468.jpeg)
>
>从上图可以看出，删除节点 C 之后的所有节点原样保留到新链表中；删除节点 C 之前的每个节点被克隆到新链表中，注意：它们在新链表中的链接顺序被反转了。
> 在执行 remove 操作时，原始链表并没有被修改，也就是说：**读线程不会受同时执行 remove 操作的并发写线程的干扰**。
> 综合上面的分析我们可以看出，**写线程对某个链表的结构性修改不会影响其他的并发读线程对这个链表的遍历访问。**
>
>**用 HashEntery 对象的不变性来降低读操作对加锁的需求**
> 在代码清单“HashEntry 类的定义”中我们可以看到，HashEntry 中的 key，hash，next 都声明为 final 型。这意味着，不能把节点添加到链接的中间和尾部，也不能在链接的中间和尾部删除节点。这个特性可以保证：**在访问某个节点时，这个节点之后的链接不会被改变。这个特性可以大大降低处理链表时的复杂性。**
>
>根据 Java 内存模型，对 同一个 volatile 变量的写 / 读操作可以确保：写线程写入的值，能够被之后未加锁的读线程”看到”。
>
>这个特性和前面介绍的 HashEntry 对象的不变性相结合，使得在 ConcurrentHashMap 中，读线程在读取散列表时，基本不需要加锁就能成功获得需要的值。这两个特性相配合，不仅减少了请求同一个锁的频率（读操作一般不需要加锁就能够成功获得值），也减少了持有同一个锁的时间（只有读到 value 域的值为 null 时 , 读线程才需要加锁后重读）。
>
>### 基于通常情形而优化
>
>在实际的应用中，散列表一般的应用场景是：除了少数插入操作和删除操作外，绝大多数都是读取操作，而且读操作在大多数时候都是成功的。正是基于这个前提，ConcurrentHashMap 针对读操作做了大量的优化。**通过 HashEntry 对象的不变性和用 volatile 型变量协调线程间的内存可见性**，使得 大多数时候，读操作不需要加锁就可以正确获得值。这个特性使得 ConcurrentHashMap 的并发性能在分离锁的基础上又有了近一步的提高。
>
>总结：
>
>在使用锁来协调多线程间并发访问的模式下，减小对锁的竞争可以有效提高并发性。有两种方式可以减小对锁的竞争：
>
>1. 减小请求 同一个锁的 频率。
>2. 减少持有锁的 时间。
>
>ConcurrentHashMap 的高并发性主要来自于三个方面：
>
>1. 用分离锁实现多个线程间的更深层次的共享访问。
>2. **用 HashEntery 对象的不变性来降低执行读操作的线程在遍历链表期间对加锁的需求。**
>3. 通过对同一个 Volatile 变量的写 / 读访问，协调不同线程间读 / 写操作的内存可见性。
>

#### [ConcurrentHashMap 1.7 和 1.8 实现上的不同](https://blog.csdn.net/weixin_44460333/article/details/86770169)


>ConcurrentHashMap 同样也分为 1.7 、1.8 版，两者在实现上略有不同。
>
>### Base 1.7
>
>1.7 的实现，下面是他的结构图：
>
>![640?wx_fmt=png](fj问题及知识点记录.assets/640.jpeg)
>
>原理上来说：**ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock。**不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。
>
>#### get 方法
>
>get 逻辑比较简单：
>
>只需要将 Key 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上。
>
>由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。
>
>ConcurrentHashMap 的 get 方法是非常高效的，**因为整个过程都不需要加锁**。
>
>### Base 1.8
>
>其中抛弃了原有的 Segment 分段锁，**而采用了 `CAS + synchronized` 来保证并发安全性。**
>
>也将 1.7 中存放数据的 HashEntry 改为 Node，但作用都是相同的。
>
>其中的 `val next` 都用了 volatile 修饰，保证了可见性。
>
>```text
>1.8 在 1.7 的数据结构上做了大的改动，采用红黑树之后可以保证查询效率（O(logn)），甚至取消了 ReentrantLock 改为了 synchronized，这样可以看出在新版的 JDK 中对 synchronized 优化是很到位的。
>```
>
>1.8之后HashMap采用尾插法不会形成环形链表.
>
>#### put 方法
>
>(Note: 取消了分段锁，改 lock 加锁的方式为 cas + synchronized)
>
>- 根据 key 计算出 hashcode 。
>- 判断是否需要进行初始化。
>- `f` 即为当前 key 定位出的 Node，**如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。**
>- 如果当前位置的 `hashcode == MOVED == -1`,则需要进行扩容。
>- 如果都不满足，则利用 synchronized 锁写入数据。
>- 如果数量大于 `TREEIFY_THRESHOLD` 则要转换为红黑树。
>
>#### get 方法
>
>- 根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。
>- 如果是红黑树那就按照树的方式获取值。
>- 就不满足那就按照链表的方式遍历获取值。

### [泛型的定义、用法与类型通配符的使用方式](https://www.cnblogs.com/fwnboke/p/8529670.html)

>#### 定义泛型方法
>
>先使用常规方法进行对比。
>
>```java
>	public static void main(String[] args) {
>		int[] arr = new int[] {1, 8, 15, 6, 3};
>		double[] douArr = {10.5, 25.1, 4.9, 1.8};
>		String[] strArr = {"我","是","字","符","串"};
>		forArr(strArr);
>	}
>	
>//遍历数组的重载方法，支持int和double类型	
>	public static void forArr(int[] arr) {
>		for(int i=0; i<arr.length; i++) {
>			System.out.println(arr[i]);
>		}
>	}
>	//重载了
>	public static void forArr(double[] arr) {
>		for(double d : arr) {
>			System.out.println(d);
>		}
>	}
>	//……
>	//……
>```
>
>如上所示，如果想遍历String类型数组，那就还要再次重载代码，如果是八种类型都有，代码量非常庞大。使用泛型方法全部通用，代码如下：
>
>```java
>	public static void main(String[] args) {
>		Integer[] arr =  {1, 8, 15, 6, 3};
>		Double[] douArr = {10.5, 25.1, 4.9, 1.8};
>		String[] strArr = {"我","是","字","符","串"};
>		
>		forArrGenric(strArr);
>		
>	}
>	//泛型方法
>	public static <T> void forArrGenric(T[] arr) {
>		for(int i=0; i < arr.length; i++) {
>			System.out.println(arr[i]);
>		}
>	}
>```
>
>只需定义一个泛型方法，根据运行时传入的参数类型，动态地获取类型，就能做到遍历所有类型数组。但需要注意，泛型的类型参数只能是引用类型，值类型无法在泛型中使用，所以上面的数组都改成了引用类型。值类型需要使用对应的包装类类型。
>
>**泛型为何不能应用于静态申明的实例解析**
>
>先给一个例子，在静态变量中和静态代码块中使用泛型。
>
>```java
>public class Test<T> {
>	public static T name;  //error
>	public T sex ;
>	
>	static {
>		T ab; //error
>	}
>}
>```
>
>报出异常：不能使一个静态引用指向一个非静态的类型 T。静态和非静态之分就在于静态是编译时类型，动态是运行时类型。T代表未知类型，如果可以用于静态申明，因为是未知类型，系统没法指定初始值，手动赋值也不行，因为不知道啥类型，只有运行时才可以指定。而泛型存在的意义就是为了动态指定具体类型，增强灵活性和通用性，所以用于静态声明违背了使用原则。为什么实例变量和实例方法可以使用呢？因为当你使用实例变量或者方法时，就说明对象存在了，即代表泛型参数也指定了。未指定具体类型默认是Object类型。
>
>## 为什么静态方法中可以定义泛型方法呢？
>
>先给三个实例，我们来慢慢分析。
>
>```java
>public class Test<T> {
>	public static void main(String[] args) {
>		
>	}
>	
>	//泛型方法
>	public T demo1(T t) {
>		return t;
>	}
>	
>	//静态方法使用泛型参数
>//	public static T demo2(T t) { return t;}
>				
>	//定义泛型静态方法
>	public static <W> void demo3(W w) {
>		System.out.println(w);
>	}  
>}
>```
>
>首先，要明确一点，泛型作用是确定具体类型。先看一个泛型方法，使用了泛型参数T作为返回值，当使用对象时来调用该方法时，T类型会变成具体类型。第二个泛型方法是静态的，使用了T作为返回值和方法参数类型，但是静态方法是属于类的，类直接调用的话，T类型无法指定具体类型，那么该方法就没有意义。所以直接报错。第三个也是静态方法，但是该静态方法是自定义一个泛型参数，并非使用类型参数。所以当传入一个具体类型时，该静态方法的<W>就是具体类型了。两者静态方法的区别就是一个是使用泛型参数，一个是定义泛型方法。

### [世界时区和Java时区详解](https://www.cnblogs.com/oldtrafford/p/9680791.html)

>### 3、UTC 时间的时间戳
>
>讲清楚了时间表达方式，再讲时间戳。其实时间戳是没有时区概念的，或者说时间戳只能是0时区的。时间戳是从1970-01-11 00:00:00+0000开始的（原因大家都知道），也就是在'1970-01-11 00:00:00+0000'这个时间点，时间戳是0。再换句话说在'1970-01-11 08:00:00+0800'时间戳也是0。这也是Java里时间组件的默认方式，不管用户输入的人类可识别的时间是什么格式，在内部统一存的是时间戳。
>
>例如时间是'2018-09-01 08:00:00+0800'，那么使用date.getTime()获取到时间戳是1535760000000；时间是'2018-09-01 00:00:00+0000'，获取到时间戳也是1535760000000。
>
>**测试代码如下：**
>
>```
>SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ssZ");
>System.out.println(sdf.parse("2018-09-01 08:00:00+0800").getTime());
>System.out.println(sdf.parse("2018-09-01 00:00:00+0000").getTime());
>```
>
>可以观察到这2行代码的输出都是1535760000000，这就证明了上面的观点。再啰嗦2点：
>
>- 第一行代码DateFormat中Z表示时区，所以String类型格式时间带上+0800这种表达式，就能正确获取时间戳了。
>- SimpleDateFormat是线程不安全的，不要用
>

### volatile

[volatile 可见性 防止指令重排](https://blog.csdn.net/weixin_40849725/article/details/106968177)

>### 详细说明：
>
>如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。
>
>| Java代码： | instance = new Singleton();//instance是volatile变量          |
>| ---------- | ------------------------------------------------------------ |
>| 汇编代码： | 0x01a3de1d: movb $0x0,0x1104800(%esi);0x01a3de24: **lock addl** $0x0,(%esp); |
>
>但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。
>所以在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，就会重新从系统内存中把数据读到处理器缓存里。
>
>### 缓存一致性协议
>
>最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU（中央处理器，central processing unit）写数据时，如果发现操作的变量是共享变量（被多个线程访问的变量），即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。
>
>防止指令重排：
>

[DCL单例模式，如何解决DCL问题](https://blog.csdn.net/qq_37001674/article/details/87984698)

>何为DCL，DCL即Double Check Lock，双重检查锁定。
>
>懒汉式
>
>```java
>public void Singleton{
>private static Singleton singleton;
>private Singleton(){}
>    
>public static Singleton getInstance(){
> if(singleton==null){
>      singleton=new Singleton();
>    }
>     
>       return singleton;
> }
>     }
>```
>
>这种方法在单线程下是可取的，但是在并发也就是在多线程的情况下是不可取的，因为其无法保证线程安全，优化如下：
>
> ```java
>public void Singleton{
>private static Singleton singleton;
>
>    private Singleton(){}
> 
>    public synchronized static Singleton getInstance(){
>    if(singleton==null){
>              singleton=new Singleton();
>        }
>     
>        return singleton;
> }
>     
>    }
> ```
>
>优化非常简单，在getInstance方法上加上了synchronized同步，尽管jdk6以后对synchronized做了优化，但还是会效率较低的，性能下降。那该如何解决这个问题？于是有人就想到了双重检查DCL
>
>```java
>public void Singleton{
>private static Singleton singleton;
>
>    private Singleton(){}
> 
>    public static Singleton getInstance(){
>    if(singleton==null){
>           synchronized(Singleton.class){
>                if(singleton==null)  singleton=new Singleton();
>            }
>     
>        }
>                 return singleton;
>     }
>     
>    }
> ```
>
>这个代码看起来perfect：
>
>1. 如果检查第一一个singleton不为null，则不需要执行加锁动作，极大的提高了性能
>2. 如果第一个singleton为null，即使有多个线程同时判断，但是由于synchronized的存在，只有一个线程能创建对象
>3. 当第一个获取锁的线程创建完成singleton对象后，其他的在第二次判断singleton一定不会为null，则直接返回已经创建好的singleton对象
>
>DCL看起来非常完美，但其实这个是不正确的。逻辑没问题，分析也没问题？但为何是不正确的？不妨我们先回顾一下创建对象的过程
>
>1. 为对象分配内存空间
>2. 初始化对象
>3. 将内存空间的地址赋值给对应的引用
>
>但由于jvm编译器的优化产生的重排序缘故，步骤2、3可能会发生重排序：
>
>1. 为对象分配内存空间
>2. 将内存空间的地址赋值给对应的引用
>3. 初始化对象
>
>如果2、3发生了重排序就会导致第二个判断会出错，singleton != null，但是它其实仅仅只是一个地址而已，此时对象还没有被初始化，所以return的singleton对象是一个没有被初始化的对象
>
>知道问题的原因，那么我们就可以解决？
>
>不允许重排序
>
>重排序不让其他线程看到
>
>### 解决方法
>
>利用volatile的特性即可阻止重排序和可见性
>
>```java
>public class Singleton {
>  //通过volatile关键字来确保安全
>  private volatile static Singleton singleton;
> 
>   private Singleton(){}
> 
>   public static Singleton getInstance(){
>       if(singleton == null){
>           synchronized (Singleton.class){
>               if(singleton == null){
>                   singleton = new Singleton();
>               }
>           }
>       }
>       return singleton;
>   }
> }
> ```
>
>类初始化的解决方案
>
>```java
>public class Singleton {
>  private static class SingletonHolder{
>      public static Singleton singleton = new Singleton();
>   }
> 
>   public static Singleton getInstance(){
>       return SingletonHolder.singleton;
>   }
> }
> ```
>
>该解决方案的根本就在于：利用classloder的机制来保证初始化instance时只有一个线程。JVM在类初始化阶段会获取一个锁，这个锁可以同步多个线程对同一个类的初始化。
>
>```text
>Java语言规定，对于每一个类或者接口C,都有一个唯一的初始化锁LC与之相对应。从C到LC的映射，由JVM的具体实现去自由实现。JVM在类初始化阶段期间会获取这个初始化锁，并且每一个线程至少获取一次锁来确保这个类已经被初始化过了。
>```

### [单例模式之六种实现方式](https://www.cnblogs.com/dafengdeai/p/12180476.html)

>#### 注意：
>
>1. 单例类只能有一个实例。
>2. 单例类必须自己创建自己的唯一实例。
>3. 单例类必须给所有其他对象提供这一实例。
>
>## 介绍
>
>#### 意图：
>
>> 保证一个类仅有一个实例，并提供一个访问它的全局访问点。
>
>#### 主要解决：
>
>> 一个全局使用的类频繁地创建与销毁。
>
>#### 何时使用：
>
>> 当您想控制实例数目，节省系统资源的时候。
>
>#### 如何解决：
>
>> 判断系统是否已经有这个单例，如果有则返回，如果没有则创建。
>
>#### 关键代码：
>
>> 构造函数是私有的。
>
>#### 优点：
>
>1. 在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例
>2. 避免对资源的多重占用（比如写文件操作）
>
>### 4、双检锁/双重校验锁（DCL，即 double-checked locking）
>
>是否 Lazy 初始化：是
>
>是否多线程安全：是
>
>实现难度：较复杂
>
>描述：这种方式采用双锁机制，安全且在多线程情况下能保持高性能。
>getInstance() 的性能对应用程序很关键。
>
>```java
>public class Singleton { 
>  // volatile 防止指令重排，
>  // 但是java1.6后直接new对象没有指令重排的问题了,需要再确定下？？？
>    private volatile static Singleton singleton;  
>    private Singleton (){}  
>    public static Singleton getSingleton() {  
>        if (singleton == null) {  
>            synchronized (Singleton.class) {  
>            if (singleton == null) {  
>                singleton = new Singleton();  
>            }  
>        }  
>    }  
>    return singleton;  
>    }  
>}
>```
>
>### 5、静态内部类
>
>**是否 Lazy 初始化：是**
>
>是否多线程安全：是
>
>实现难度：一般
>
>描述：这种方式能达到双检锁方式一样的功效，但实现更简单。对静态域使用延迟初始化，应使用这种方式而不是双检锁方式。这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。
>**这种方式同样利用了 classloader 机制来保证初始化 instance 时只有一个线程，**它跟第 3 种方式不同的是：第 3 种方式只要 Singleton 类被装载了，那么 instance 就会被实例化（没有达到 lazy loading 效果），而这种方式是 Singleton 类被装载了，instance 不一定被初始化。**因为 SingletonHolder 类没有被主动使用，只有通过显式调用 getInstance 方法时，才会显式装载 SingletonHolder 类，从而实例化 instance。想象一下，如果实例化 instance 很消耗资源，所以想让它延迟加载，另外一方面，又不希望在 Singleton 类加载时就实例化，因为不能确保 Singleton 类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化 instance 显然是不合适的。这个时候，这种方式相比第 3 种方式就显得很合理。**
>
>```java
>public class Singleton {  
>    private static class SingletonHolder {  
>        private static final Singleton INSTANCE = new Singleton();  
>    }  
>    private Singleton (){}  
>    public static final Singleton getInstance() {  
>        return SingletonHolder.INSTANCE;  
>    }  
>}
>```
>
>### 6、枚举   （不懂？？？）
>
>JDK 版本：JDK1.5 起
>
>是否 Lazy 初始化：否
>
>是否多线程安全：是
>
>实现难度：易
>
>描述：这种实现方式还没有被广泛采用，但这是实现单例模式的最佳方法。它更简洁，自动支持序列化机制，绝对防止多次实例化。
>这种方式是 Effective Java 作者 Josh Bloch 提倡的方式，它不仅能避免多线程同步问题，而且还自动支持序列化机制，防止反序列化重新创建新的对象，绝对防止多次实例化。不过，由于 JDK1.5 之后才加入 enum 特性，用这种方式写不免让人感觉生疏，在实际工作中，也很少用。
>不能通过 reflection attack 来调用私有构造方法。
>
>```java
>public enum StringUtil {
>    INSTANCE;
>    public int str2Int(String str){
>        return Integer.parseInt(str);
>    }
>}
>```

### [Java正则表达式详解](https://www.jianshu.com/p/d47851245dba)

### [Java ServiceLoader使用和解析](https://blog.csdn.net/shi2huang/article/details/80308531)

>一、使用场景
>一般使用接口的实现类都是静态new一个实现类赋值给接口引用，如下：
>
>HelloService service = new HelloImpl();
>
>如果需要动态的获取一个接口的实现类呢？全局扫描全部的Class，然后判断是否实现了某个接口？代价太大，一般不会这么做。一种合适的方式就是使用配置文件，把实现类名配置在某个地方，然后读取这个配置文件，获取实现类名。JDK给我们提供的TestServiceLoader 就是这种方式。
>
>二、使用方式
>
>在实现类的jar包的META-INF下新建一个文件夹services，并在services下新建一个文件，以接口的全限定名为文件名，内容为实现类的全限定名。
>
>通过以下的例子来分析实现原理.
>
>1. 新建一个接口，2个实现类。
>
>```java
>package com.test.loader;
>public interface HelloService {
>	public void sayHello();
>}
>package com.test.loader;
>public class Dog implements HelloService {
>@Override
>public void sayHello() {
>System.out.println("bark bark bark...");
>}
>}
>package com.test.loader;
>public class Sheep implements HelloService {
>@Override
>public void sayHello() {
>	System.out.println("bleat bleat bleat...");
>}
>}
>```
>
>2. 分别把接口、2个实现类打成3个jar包，放在D盘下。
>
>![img](https://img-blog.csdn.net/2018051413445128?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaTJodWFuZw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
>
>3. 在Dog.jar、Sheep.jar 分别加上META-INF下新建一个文件夹services，并在services下新建一个文件，以接口的全限定名为文件名，内容为实现类的全限定名。如下：
>
>![img](https://img-blog.csdn.net/20180514134458463?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaTJodWFuZw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
>
>4. 使用指定的ClassLoader不包含实现类
>
>```java
>public static void notInTheClassLoader() throws MalformedURLException {
>		ClassLoader serviceCL = new URLClassLoader(new URL[] { new URL("file:" + "D:/HelloService.jar") }, TestServiceLoader.class.getClassLoader().getParent());
>		/* 指定的ClassLoader没有实现类，所以扫描不到META-INF/services/com.test.loader.HelloService */
>		ServiceLoader<HelloService> helloServices = ServiceLoader.load(HelloService.class, serviceCL);
>		Iterator<HelloService> it = helloServices.iterator();
>		while (it.hasNext()) {
>			HelloService service = it.next();
>			service.sayHello();
>		}
>	}
>```
>
>结果不会打印任何信息。
>
>5. 指定的ClassLoader包含实现类
>
>```java
>public static void inTheClassLoader() throws MalformedURLException {
>ClassLoader serviceCL = new URLClassLoader(new URL[] { new URL("file:" + "D:/Dog.jar"), new URL("file:" + "D:/Sheep.jar") },TestServiceLoader.class.getClassLoader().getParent());
>/* 实现类在指定的ClassLoader，所以可以扫描META-INF/services/com.test.loader.HelloService */
> ServiceLoader<HelloService> helloServices = ServiceLoader.load(HelloService.class, serviceCL);
>		Iterator<HelloService> it = helloServices.iterator();
>	while (it.hasNext()) {
>			HelloService service = it.next();
>			service.sayHello();
>		}
>	}
>```
>
>结果如下：
>
>```properties
>bark bark bark...
>bleat bleat bleat...
>```
>
>6. 使用指定的ClassLoader加载接口类，不指定ClassLoader加载实现类。
>
>```java
>public static void defaultClassLoader() throws MalformedURLException, ClassNotFoundException {
>		ClassLoader serviceCL = new URLClassLoader(new URL[] { new URL("file:" + "D:/HelloService.jar"),
>				new URL("file:" + "D:/Dog.jar"), new URL("file:" + "D:/Sheep.jar") },
>				TestServiceLoader.class.getClassLoader().getParent());
>		/* 默认会使用 ClassLoader.getSystemClassLoader() */
>		ServiceLoader<HelloService> helloServices = ServiceLoader
>				.load(
>         (Class<HelloService>) (serviceCL.loadClass("com.test.loader.HelloService")));
>		Iterator<HelloService> it = helloServices.iterator();
>		while (it.hasNext()) {
>			HelloService service = it.next();
>			service.sayHello();
>		}
>	}
>```
>
>结果不打印任何信息。
>
>7. 把2个实现jar加到工程的Build Path里面，不指定ClassLoader。
>
>![img](https://img-blog.csdn.net/20180514134627592?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaTJodWFuZw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
>
>```java
>public static void notSpecifyClassLoader() {
>
>		ServiceLoader<HelloService> helloServices = ServiceLoader.load(HelloService.class);
>		Iterator<HelloService> it = helloServices.iterator();
>		while (it.hasNext()) {
>      HelloService service = it.next();
>		   service.sayHello();
>		}
>	}
>```
>
>结果如下：
>
>```properties
>bark bark bark...
>
>bleat bleat bleat...
>```
>

### [背压(Back Pressure)与流量控制](https://lotabout.me/2020/Back-Pressure/)

>背压(back pressure)，也叫“反压”，指的是下游系统处理过慢，导致上游系统阻塞的现象。我们来聊聊背压后面的流控吧。
>
>## 流控策略
>
>如上图，系统中存在三方：生产者(Producer)产生数据，通过管道(Pipeline)传输给消费者(Consumer)。
>
>![Producer Consumer](https://lotabout.me/2020/Back-Pressure/Producer-Consumer.svg)
>
>此时生产的速率(100/s)大于消费的速率(75/s)，多余的流量无处可去。于是自然地衍生出三种策略：
>
>1. 控制(Control)。降低生产速率，从源头减少流量
>2. 缓冲(Buffer)。管道将多余的流量存储起来
>3. 丢弃(Drop)。消费者将无暇处理的流量丢弃
>
>由于“控制”策略需要将消费者的压力反馈给生产者，从而降低生产速率，与“背压”现象很类似，因此在资料中背压也常常代指“控制”策略。

### [volatile 可见性 防止指令重排](https://blog.csdn.net/weixin_40849725/article/details/106968177)

># 指令重排
>
>指令重排是指在程序执行过程中, 为了性能考虑, 编译器和CPU可能会对指令重新排序.
>可参考：[Java内存模型与指令重排](https://www.cnblogs.com/xdecode/p/8948277.html).
>
>## 指令重排遵循的原则
>
>### as-if-serial原则
>
>[as-if-serial](https://www.cnblogs.com/jiuya/p/10791903.html)
>不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。
>编译器，runtime 和处理器都必须遵守as-if-serial语义，（把单线程程序保护了起来）。
>为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。
>
>### happens-before原则
>
>![在这里插入图片描述](https://img-blog.csdnimg.cn/20200626113519425.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDg0OTcyNQ==,size_16,color_FFFFFF,t_70)
>
>## 指令重排序导致的问题
>
>在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。

### [@PostConstruct和@PreDestroy的使用说明](https://blog.csdn.net/qa275267067/article/details/89495290)

>有些需要在项目启动时执行的方法，如设置全局环境语言变量等，需要用到@PostConstruct注解，在此记录一下。
>
>1.@PostConstruct说明
>
>   被@PostConstruct修饰的方法会在服务器加载Servlet的时候运行，并且只会被服务器调用一次，类似于Servlet的inti()方法。被@PostConstruct修饰的方法会在构造函数之后，init() 方法之前运行。
>
>2.@PreDestroy说明
>
> 被@PreDestroy修饰的方法会在服务器卸载Servlet的时候运行，并且只会被服务器调用一次，类似于Servlet的destroy()方法。被@PreDestroy修饰的方法会在destroy()方法之后运行，在Servlet被彻底卸载之前。

### 理解 java.io.ObjectInputStream 和 java.io.ObjectOutputStream ？？？

java.io.ObjectOutputStream#annotateClass

java.io.ObjectInputStream#resolveObject

### 利用try-with-resource机制关闭连接

>JDK1.7之后有了try-with-resource处理机制。首先被自动关闭的资源需要实现Closeable或者AutoCloseable接口，因为只有实现了这两个接口才可以自动调用close()方法去自动关闭资源。写法为try(){}catch(){}，将要关闭的外部资源在try()中创建，catch()捕获处理异常。其实try-with-resource机制是一种语法糖，其底层实现原理仍然是try{}catch(){}finally{}写法，不过在catch(){}代码块中有一个addSuppressed()方法，即异常抑制方法。如果业务处理和关闭连接都出现了异常，业务处理的异常会抑制关闭连接的异常，只抛出处理中的异常，仍然可以通过getSuppressed()方法获得关闭连接的异常。
>————————————————
>版权声明：本文为CSDN博主「滴哩哩哩滴哩哩哩哒哒」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
>原文链接：https://blog.csdn.net/weixin_42447959/article/details/81192098
>
>Java try-with-resource语句
>
>![image-20210624120420080](fj问题及知识点记录.assets/image-20210624120420080.png)



### java 的 RMI机制？？？

### [JAVA学习篇--静态代理VS动态代理](https://blog.csdn.net/hejingyuan6/article/details/36203505)

>Proxy 代理模式是一种结构型设计模式，主要解决的问题是：在直接访问对象时带来的问题。
>
>代理是一种常用的设计模式，其目的就是为其他对象提供一个代理以控制对某个对象的访问。
>
>AOP只是在对OOP的基础上进行进一步抽象，使我们的类的职责更加单一。
>
>![image-20210204144419863](./fj问题及知识点记录.assets/image-20210204144419863.png)
>
>按照代理的创建时期，代理类可以分为两种： 
>
>**静态：由程序员创建代理类或特定工具自动生成源代码再对其编译。在程序运行前代理类的.class文件就已经存在了。**
>
>**动态：在程序运行时运用反射机制动态创建而成。**
>
>* 静态代理类优缺点
>
>优点：
>
>代理使客户端不需要知道实现类是什么，怎么做的，而客户端只需知道代理即可（解耦合），对于如上的客户端代码，newUserManagerImpl()可以应用工厂将它隐藏，如上只是举个例子而已。
>
>缺点：
>
>1）代理类和委托类实现了相同的接口，代理类通过委托类实现了相同的方法。这样就出现了大量的代码重复。如果接口增加一个方法，除了所有实现类需要实现这个方法外，所有代理类也需要实现此方法。增加了代码维护的复杂度。
>
>2）**代理对象只服务于一种类型的对象，如果要服务多类型的对象。势必要为每一种对象都进行代理，静态代理在程序规模稍大时就无法胜任了。如上的代码是只为UserManager类的访问提供了代理，但是如果还要为其他类如Department类提供代理的话，就需要我们再次添加代理Department的代理类。**
>
>2.动态代理类
>与静态代理类对照的是动态代理类，动态代理类的字节码在程序运行时由Java反射机制动态生成，无需程序员手工编写它的源代码。动态代理类不仅简化了编程工作，而且提高了软件系统的可扩展性，因为Java 反射机制可以生成任意类型的动态代理类。java.lang.reflect 包中的Proxy类和InvocationHandler 接口提供了生成动态代理类的能力。
>Proxy类提供了创建动态代理类及其实例的静态方法。
>（1）getProxyClass()静态方法负责创建动态代理类，它的完整定义如下：
>public static Class<?> getProxyClass(ClassLoader loader, Class<?>[] interfaces) throws IllegalArgumentException
>参数loader 指定动态代理类的类加载器，参数interfaces 指定动态代理类需要实现的所有接口。
>（2）newProxyInstance()静态方法负责创建动态代理类的实例，它的完整定义如下：
>public static Object newProxyInstance(ClassLoader loader, Class<?>[] interfaces, InvocationHandler handler) throws
>IllegalArgumentException
>参数loader 指定动态代理类的类加载器，参数interfaces 指定动态代理类需要实现的所有接口，参数handler 指定与动态代理类关联的 InvocationHandler 对象。
>以下两种方式都创建了实现Foo接口的动态代理类的实例：
>*方式一 
>//创建InvocationHandler对象
>InvocationHandler handler = new MyInvocationHandler(...);
>//创建动态代理类
>Class proxyClass = Proxy.getProxyClass(Foo.class.getClassLoader(), new Class[] { Foo.class });
>//创建动态代理类的实例
>Foo foo = (Foo) proxyClass.getConstructor(new Class[] { InvocationHandler.class }).
>newInstance(new Object[] { handler });
>*方式二 
>//创建InvocationHandler对象
>InvocationHandler handler = new MyInvocationHandler(...);
>//直接创建动态代理类的实例
>Foo foo = (Foo) Proxy.newProxyInstance(Foo.class.getClassLoader(),new Class[] { Foo.class }, handler);
>由Proxy类的静态方法创建的动态代理类具有以下特点：
>动态代理类是public、final和非抽象类型的；
>动态代理类继承了java.lang.reflect.Proxy类；
>动态代理类的名字以“$Proxy”开头；
>动态代理类实现getProxyClass()和newProxyInstance()方法中参数interfaces指定的所有接口；

### [java不同的包下相同的类名的问题与解决办法](https://www.cnblogs.com/yanggb/p/10650256.html)

>第二个问题，不同的jar里面相同的包名类名怎么去区别导入。
>
>这个问题与标题不符，标题是不同的包，这里的问题是不同的jar，虽然跑题了，但是还是可以归类到这里。
>
>具体问题是，如果两个jar包里面有相同的包，有相同的类名，如果同时引用了这两个jar，就可能会产生引用的类不对的问题。
>
>要知道这个问题产生的原因，就要了解JVM加载的方法。JVM在加载包的时候，是按CLASSPATH的路径从上往下找，找到第一个后就将这个包引用。
>
>这时如果包名和类名都相同，那么JVM就没法区分了。一般来说我们用的IDE都是会提示发生冲突而报错的，如果不报错的话，那么就只有第一个包被引入，即在CLASSPATH路径下排在前面的包，第二个包会在classLoader加载类的时候判断重复而忽略。
>
>知道了JVM加载包的方法，那么解决问题就很容易了，只需要将需要引用包的jar放在前边就可以了，也就是说放在CLASSPATH路径下前沿的位置。

### [受检异常和非受检异常的区别](https://blog.csdn.net/weixin_39506180/article/details/106720843)

>**非受检异常（RuntimeException）**：这类异常是编程人员的逻辑问题，不需要对异常进行捕获或者抛出。程序自动输入异常信息，常见的异常有：NullPointerException,ClassCastException,ArrayIndexsOutOfBoundsException.
>
>**受检异常（非RuntimeException）**：这类异常是由一些外部的偶然因素所引起的，**必须对该类型的异常进行捕获或者抛出**；受检异常可以控制义务逻辑，可在catch中处理异常带了的问题，常见的异常有：Exception, FileNotFoundException, IOException, SQLException。
>![image-20210319164555536](./fj问题及知识点记录.assets/image-20210319164555536.png)
>
>两者的差异和优缺点:
>受检异常是通过继承 Exception 来实现的.
>非受检异常是通过继承 RuntimeException 来实现的.
>
>受检异常降低代码的可读性，也可以影响代码规范的原则。
>当受检异常威胁到系统的稳定性、安全性、可靠性的时候必须进行处理，不能转换成非受检异常。其他情况下可转换成非受检异常。

### h3 [为什么阿里巴巴Java开发手册中强制要求接口返回值不允许使用枚举？](https://blog.csdn.net/qq_27276045/article/details/106152887)

>由于升级原因，导致双方的枚举类不尽相同，在接口解析，类反序列化时出现异常。
>
>Java 中出现的任何元素，在 Gosling 的角度都会有背后的思考和逻辑（尽管并非绝对完美，但 Java 的顶层抽象已经是天才级了），比如：接口、抽象类、注解、和本文提到的枚举。枚举有好处，类型安全，清晰直接，还可以使用等号来判断，也可以用在 switch 中。它的劣势也是明显的，就是不要扩展。可是为什么在返回值和参数进行了区分呢，如果不兼容，那么两个都有问题，怎么允许参数可以有枚举。当时的考虑，如果参数也不能用，那么枚举几乎无用武之地了。参数输入，毕竟是本地决定的，你本地有的，传送过去，向前兼容是不会有问题的。但如果是接口返回，就比较恶心了，因为解析回来的这个枚举值，可能本地还没有，这时就会抛出序列化异常。
>
>比如：你的本地枚举类，有一个天气 Enum：SUNNY, RAINY, CLOUDY，如果根据天气计算心情的方法：guess(WeatcherEnum xx)，传入这三个值都是可以的。返回值：Weather guess(参数)，那么对方运算后，返回一个 SNOWY，本地枚举里没有这个值，傻眼了。

### [自定义注解详细介绍](https://blog.csdn.net/xsp_happyboy/article/details/80987484)   实用，清晰

>2.1 基本语法
>注解类型的声明部分：
>
>注解在Java中，与类、接口、枚举类似，因此其声明语法基本一致，只是所使用的关键字有所不同@interface。在底层实现上，所有定义的注解都会自动继承java.lang.annotation.Annotation接口。
>
>```java
>public @interface CherryAnnotation {
>}
>```
>
>注解类型的实现部分：
>
>根据我们在自定义类的经验，在类的实现部分无非就是书写构造、属性或方法。但是，在自定义注解中，其实现部分只能定义一个东西：注解类型元素（annotation type element）。咱们来看看其语法：
>
>```java
>public @interface CherryAnnotation {
>	public String name();
>	int age();
>	int[] array();
>}
>```
>
>也许你会认为这不就是接口中定义抽象方法的语法嘛？别着急，咱们看看下面这个：
>
>```java
>public @interface CherryAnnotation {
>	public String name();
>	int age() default 18;
>	int[] array();
>}
>
>```
>
>看到关键字default了吗？还觉得是抽象方法吗？
>
>注解里面定义的是：注解类型元素！
>
>定义注解类型元素时需要注意如下几点：
>
>**访问修饰符必须为public，不写默认为public；**
>**该元素的类型只能是基本数据类型、String、Class、枚举类型、注解类型（体现了注解的嵌套效果）以及上述类型的一位数组；**
>**该元素的名称一般定义为名词，如果注解中只有一个元素，请把名字起为value（后面使用会带来便利操作）；**
>**()不是定义方法参数的地方，也不能在括号中定义任何参数，仅仅只是一个特殊的语法；**
>**default代表默认值，值必须和第2点定义的类型一致；**
>**如果没有默认值，代表后续使用注解时必须给该类型元素赋值。**
>**可以看出，注解类型元素的语法非常奇怪，即又有属性的特征（可以赋值）,又有方法的特征（打上了一对括号）**。
>
>但是这么设计是有道理的，我们在后面的章节中可以看到：**注解在定义好了以后，使用的时候操作元素类型像在操作属性，解析的时候操作元素类型像在操作方法。**
>
>2.2 常用的元注解
>一个最最基本的注解定义就只包括了上面的两部分内容：1、注解的名字；2、注解包含的类型元素。但是，我们在使用JDK自带注解的时候发现，有些注解只能写在方法上面（比如@Override）；有些却可以写在类的上面（比如@Deprecated）。当然除此以外还有很多细节性的定义，那么这些定义该如何做呢？接下来就该元注解出场了！
>元注解：专门修饰注解的注解。它们都是为了更好的设计自定义注解的细节而专门设计的。我们为大家一个个来做介绍。
>
>2.2.1 @Target
>@Target注解，是专门用来限定某个自定义注解能够被应用在哪些Java元素上面的。它使用一个枚举类型定义如下：
>
>```java
>public enum ElementType {
>    /** 类，接口（包括注解类型）或枚举的声明 */
>    TYPE,
>/** 属性的声明 */
>FIELD,
>
>/** 方法的声明 */
>METHOD,
>
>/** 方法形式参数声明 */
>PARAMETER,
>
>/** 构造方法的声明 */
>CONSTRUCTOR,
>
>/** 局部变量声明 */
>LOCAL_VARIABLE,
>
>/** 注解类型声明 */
>ANNOTATION_TYPE,
>
>/** 包的声明 */
>PACKAGE
>}
>```
>
>//@CherryAnnotation被限定只能使用在类、接口或方法上面
>
>```java
>//@CherryAnnotation被限定只能使用在类、接口或方法上面
>@Target(value = {ElementType.TYPE,ElementType.METHOD})
>public @interface CherryAnnotation {
>    String name();
>    int age() default 18;
>    int[] array();
>}
>
>```
>
>2.2.2 @Retention
>@Retention 注解，翻译为持久力、保持力。即用来修饰自定义注解的生命力。
>注解的生命周期有三个阶段：1、Java源文件阶段；2、编译到class文件阶段；3、运行期阶段。同样使用了RetentionPolicy枚举类型定义了三个阶段：
>
>```java
>public enum RetentionPolicy {
>    /**
>     * Annotations are to be discarded by the compiler.
>     * （注解将被编译器忽略掉）
>     */
>    SOURCE,
>
>    /**
>     * Annotations are to be recorded in the class file by the compiler
>     * but need not be retained by the VM at run time.  This is the default
>     * behavior.
>     * （注解将被编译器记录在class文件中，但在运行时不会被虚拟机保留，这是一个默认的行为）
>     */
>    CLASS,
>
>    /**
>     * Annotations are to be recorded in the class file by the compiler and
>     * retained by the VM at run time, so they may be read reflectively.
>     * （注解将被编译器记录在class文件中，而且在运行时会被虚拟机保留，因此它们能通过反射被读取到）
>     * @see java.lang.reflect.AnnotatedElement
>     */
>    RUNTIME
>}
>
>```
>
>我们再详解一下：
>
>如果一个注解被定义为RetentionPolicy.SOURCE，则它将被限定在Java源文件中，那么这个注解即不会参与编译也不会在运行期起任何作用，这个注解就和一个注释是一样的效果，只能被阅读Java文件的人看到；
>如果一个注解被定义为RetentionPolicy.CLASS，则它将被编译到Class文件中，那么编译器可以在编译时根据注解做一些处理动作，但是运行时JVM（Java虚拟机）会忽略它，我们在运行期也不能读取到；
>如果一个注解被定义为RetentionPolicy.RUNTIME，那么这个注解可以在运行期的加载阶段被加载到Class对象中。那么在程序运行阶段，我们可以通过反射得到这个注解，并通过判断是否有这个注解或这个注解中属性的值，从而执行不同的程序代码段。我们实际开发中的自定义注解几乎都是使用的RetentionPolicy.RUNTIME；
>在默认的情况下，自定义注解是使用的RetentionPolicy.CLASS。
>2.2.3 @Documented
>@Documented注解，是被用来指定自定义注解是否能随着被定义的java文件生成到JavaDoc文档当中。
>
>2.2.4 @Inherited
>@Inherited注解，是指定某个自定义注解如果写在了父类的声明部分，那么子类的声明部分也能自动拥有该注解。@Inherited注解只对那些@Target被定义为ElementType.TYPE的自定义注解起作用。
>————————————————
>版权声明：本文为CSDN博主「cherry-peng」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
>原文链接：https://blog.csdn.net/xsp_happyboy/article/details/80987484



### h3   guava 官方文档

https://github.com/google/guava/wiki



## [Apache HttpComponents](http://hc.apache.org/index.html)

![image-20210705185357158](fj问题及知识点记录.assets/image-20210705185357158.png)

## [@JsonFormat与@DateTimeFormat注解的使用](https://www.cnblogs.com/mracale/p/9828346.html)

>在 controller 层我们使用 spring mvc 表单自动封装映射对象时，我们在对应的接收前台数据的对象的属性上加@@DateTimeFormat
>
>```
>@DateTimeFormat(pattern = ``"yyyy-MM-dd"``)``@JsonFormat(pattern = ``"yyyy-MM-dd HH:mm:ss"``,timezone=``"GMT+8"``)``private` `Date symstarttime;` `@DateTimeFormat(pattern = ``"yyyy-MM-dd"``)``@JsonFormat(pattern = ``"yyyy-MM-dd HH:mm:ss"``,timezone=``"GMT+8"``)``private` `Date symendtime;
>```
>
>　　我这里就只贴这两个属性了，这里我两个注解都同时使用了，因为我既需要取数据到前台，也需要前台数据传到后台，都需要进行时间格式的转换，可以同时使用
>
>3.通过上面两个步骤之后，我们就可以获取一个符合自定义格式的时间格式存储到数据库了
>
>总结： 
>
> 注解@JsonFormat主要是后台到前台的时间格式的转换.
>
> 注解@DataFormAT主要是前后到后台的时间格式的转换.

**Java Integer(-128~127)**值的**==**和**equals**比较产生的思考

https://blog.csdn.net/chengzhezhijian/article/details/9628251

>**<-128~127**以内的**Integer**值，**Integer x = value;**的方式赋值！**>**
>
>**i=127,j =127**
>
>**i == j**：**true<--**比较**-->i.equals(j):true**
>
>**<-128~127**以外的**Integer**值，**Integer x = value;**的方式赋值！**>**
>
>**m=128,n =128**
>
>**m == n**：**false<--**比较**-->m.equals(n):true**
>
>**<**任意**Integer**值，**Integer x = new Integer(value);**的方式赋值！**>**
>
>**x=299,y =299**
>
>**1**、以上代码第一段和第二段旨在说明：在**-128~127**的**Integer**值并且以**Integer x = value;**的方式赋值的**Integer**值在进行**==**和**equals**比较时，都会返回**true**，数值之间==也是比较的对象地址值，可是都取的静态数组里面的integer对象，所以是一样的，超过就会创建新的integer对象。
>
>**2**、第三段旨在说明：**==**和**equals**的区别，**==**是进行地址及值比较，无法对**==**操作符进行重载，而对于**equals**方法，**Integer**里面的**equals**方法重写了**Object**的**equals**方法，查看**Integer**源码可以看出**equals**方法进行的是数值比较。
>
>这儿的IntegerCache有一个静态的Integer数组，在类加载时就将-128 到 127 的Integer对象创建了，并保存在cache数组中，一旦程序调用valueOf 方法，如果i的值是在-128 到 127 之间就直接在cache缓存数组中去取Integer对象。
>
>***使用Oracle/Sun JDK 6，在server模式下，使用-XX:AutoBoxCacheMax=NNN参数即可将Integer的自动缓存区间设置为[-128,NNN]。注意区间的下界固定在-128不可配置。***
>
>在设置了-XX:+AggressiveOpts启动参数后，AutoBoxCacheMax 的默认值会被修改为 20000 并且生效。



## 线程池和信号量的区别？

Semaphore和线程池的差异
https://zhuanlan.zhihu.com/p/111038801

2. Semaphore和线程池的区别
先亮结果，Semaphore和线程池的区别如下：

使用Semaphore，实际工作线程由开发者自己创建；使用线程池，实际工作线程由线程池创建.
使用Semaphore，并发线程的控制必须手动通过acquire()和release()函数手动完成；使用线程池，并发线程的控制由线程池自动管理.
使用Semaphore不支持设置超时和实现异步访问；使用线程池则可以实现超时和异步访问，通过提交一个Callable对象获得Future，从而可以在需要时调用Future的方法获得线程执行的结果，同样利用Future也可以实现超时.

用Semaphore实现互斥锁
使用信号值为1的Semaphore对象便可以实现互斥锁，示例如下：

``` java
public static void testSemaphoreMutex() {
    Semaphore semaphore = new Semaphore(1);
    for (int i = 0; i < 6; i++) {
        new Thread() {
            public void run() {
                try {
                    semaphore.acquire();
                    System.out.println(Thread.currentThread().getName() + " get semaphore");
                    Thread.sleep(2000);
                    System.out.println(Thread.currentThread().getName() + " release semaphore");
                    semaphore.release();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }.start();
    }
}
```

可以看出，任何一个线程在释放许可之前，其它线程都拿不到许可。这样当前线程必须执行完毕，其它线程才可执行，这样就实现了互斥。

4. Semaphore 的易错点
使用Semophore时有一个非常容易犯错误的地方，即先release再acqure后会导致Semophore管理的虚拟许可额外新增一个.



## [悲观锁、乐观锁](https://blog.csdn.net/qq_34337272/article/details/81072874)

>悲观锁
>**总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁**，这样别人想拿这个数据就会阻塞直到它拿到锁（**共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。
>
>乐观锁：适用于多读的应用类型
>**总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量**，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。
>
>**两种锁的使用场景
>从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。**
>
>**CAS与synchronized的使用情景**
>**简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多）**
>
>对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。
>对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。
>补充： **Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称它为 “重量级锁” 。但是，在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的 偏向锁 和 轻量级锁 以及其它各种优化之后变得在某些情况下并不是那么重了。synchronized的底层实现主要依靠 Lock-Free 的队列，基本思路是 自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。**



## Java里一个线程调用了Thread.interrupt()到底意味着什么？

https://www.zhihu.com/question/41048032/answer/89431513

首先，一个线程不应该由其他线程来强制中断或停止，而是应该由线程自己自行停止。

所以，Thread.stop, Thread.suspend, Thread.resume 都已经被废弃了。

而 Thread.interrupt 的作用其实也不是中断线程，而是「[通知线程](https://www.zhihu.com/search?q=通知线程&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A89431513})应该中断了」，

**具体到底中断还是继续运行，应该由被通知的线程自己处理。**

具体来说，当对一个线程，调用 interrupt() 时，

**① 如果线程处于被阻塞状态（例如处于sleep, wait, join 等状态），那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常。仅此而已。**

**② 如果线程处于正常活动状态，那么会将该线程的中断标志设置为 true，仅此而已。被设置中断标志的线程将继续正常运行，不受影响。**

interrupt() 并不能真正的中断线程，需要被调用的线程自己进行配合才行。

也就是说，一个线程如果有被中断的需求，那么就可以这样做。

**① 在正常运行任务时，经常检查本线程的中断标志位，如果被设置了中断标志就自行停止线程。**

**② 在调用[阻塞方法](https://www.zhihu.com/search?q=阻塞方法&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A89431513})时正确处理InterruptedException异常。（例如，catch异常后就结束线程。**



## Nginx 专题   #####

* nginx 常用命令

```shell
# linux/mac启动
$ service nginx start
# 手动指定配置
$ nginx -c /usr/local/nginx/conf/nginx.conf
# -p指定nginx运行目录(日志存储位置)
$ nginx -c /path/nginx.conf -p /path/
# 重启
$ nginx -s reload
# 关闭
$ nginx -s stop
# 查看nginx.conf配置文件位置
nginx -t
```

* nginx 配置文件解析

[nginx常用配置文件解析](https://www.jianshu.com/p/cee15a00728b)

>**server虚拟主机配置**
>
>http服务上支持若干虚拟主机。每个虚拟主机一个对应的server配置项，配置项里面包含该虚拟主机相关的配置。在提供mail服务的代理时，也可以建立若干server。每个server通过监听地址或端口来区分。
>
>### listen
>
>监听端口，默认80，小于1024的要以root启动。可以为listen *:80、listen 127.0.0.1:80等形式。
>
>### server_name
>
>服务器名，如localhost、[www.example.com](https://links.jianshu.com/go?to=http%3A%2F%2Fwww.example.com)，可以通过正则匹配。
>
>## location配置
>
>http服务中，某些特定的URL对应的一系列配置项
>
>### root /var/www/html
>
>定义服务器的默认网站根目录位置。如果locationURL匹配的是子目录或文件，root没什么作用，一般放在server指令里面或/下。
>
>### index index.jsp index.html index.htm
>
>定义路径下默认访问的文件名，一般跟着root放
>
>### proxy_pass http:/backend
>
>**请求转向backend定义的服务器列表，即反向代理，对应upstream负载均衡器**。也可以proxy_pass [http://ip:port](https://links.jianshu.com/go?to=http%3A%2F%2Fip%3Aport)。

* [Nginx配置中的log_format用法梳理（设置详细的日志格式）](https://www.cnblogs.com/kevingrace/p/5893499.html)

>```
>参数           说明                     示例
>$remote_addr       客户端地址                  211.28.65.253
>$remote_user       客户端用户名称                --
>$time_local       访问时间和时区                18``/Jul/2012``:17:00:01 +0800
>$request         请求的URI和HTTP协议              ``"GET /article-10000.html HTTP/1.1"
>$http_host        请求地址，即浏览器中你输入的地址（IP或域名）   www.wang.com 192.168.100.100
>$status         HTTP请求状态                 200
>$upstream_status     upstream状态                 200
>$body_bytes_sent     发送给客户端文件内容大小            1547
>$http_referer      url跳转来源                  https:``//www``.baidu.com/
>$http_user_agent     用户终端浏览器等信息              "Mozilla``/4``.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident``/4``.0; SV1; GTB7.0; .NET4.0C;
>$ssl_protocol      SSL协议版本                  TLSv1
>$ssl_cipher       交换数据中的算法                RC4-SHA
>$upstream_addr      后台upstream的地址，即真正提供服务的主机地址   10.10.10.100:80
>$request_time      整个请求的总时间                0.205
>$upstream_response_time 请求过程中，upstream响应时间          0.002
>```

* [nginx 中通过server_name listen的方式配置多个服务器](https://blog.csdn.net/thlzjfefe/article/details/84489311)

>nginx作为代理服务器部署在主机 A 上面，B 和 C 作为两台应用服务器。现在想实现通过A访问B和C，有以下两种方式：
>
>一、通过不同的listen实现对B和C的访问，实现方式如下：在nginx.conf中添加两个server
>
>server {
>            listen  8081;
>            server_name test1;
>            location / {
>                proxy_pass http://192.168.1.168:9093;
>            }
>   }
>
>server {
>            listen  8082;
>            server_name test2;
>            location / {
>                proxy_pass http://192.168.1.169:9093;
>            }
>   }
>
>注意：1、在以上配置中，server_name 可以任意取名。
>
>           2、主机B的访问方式通过A监听端口8081来代理，访问方式：http://192.168.1.167:8081
>                                                                    
>           3、主机C的访问方式通过A监听端口8082来代理，访问方式：http://192.168.1.167:8082
>
>二、通过相同的listen，不同的server_name实现对B和C的访问，即通过不同的域名方式访问B和C，实现方式如下：
>
>server {
>            listen  8080;
>            server_name www.test1.com;
>            location / {
>                proxy_pass http://192.168.1.168:9093;
>            }
>   }
>
>server {
>            listen  8080;
>            server_name www.test2.com;
>            location / {
>                proxy_pass http://192.168.1.169:9093;
>            }
>   }
>————————————————
>版权声明：本文为CSDN博主「thlzjfefe」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
>原文链接：https://blog.csdn.net/thlzjfefe/article/details/84489311

Nginx 日志

* [Configuring Logging](https://docs.nginx.com/nginx/admin-guide/monitoring/logging/)

>Another example of the log format enables tracking different time values between NGINX and an upstream server that may help to diagnose a problem if your website experience slowdowns. You can use the following variables to log the indicated time values:
>
>- [`$upstream_connect_time`](https://nginx.org/en/docs/http/ngx_http_upstream_module.html?&_ga=2.138239600.17528474.1591347329-1120404259.1591347329#var_upstream_connect_time) – The time spent on establishing a connection with an upstream server
>- [`$upstream_header_time`](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#var_upstream_header_time) – The time between establishing a connection and receiving the first byte of the response header from the upstream server
>- [`$upstream_response_time`](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#var_upstream_response_time) – The time between establishing a connection and receiving the last byte of the response body from the upstream server
>- [`$request_time`](https://nginx.org/en/docs/http/ngx_http_log_module.html#var_request_time) – The total time spent processing a request

* [FastCGI介绍及Nginx fastcgi配置优化](https://www.cnblogs.com/xiewenming/p/8109292.html)

* [[FastCGI - 维基百科，自由的百科全书](https://zh.wikipedia.org/zh-hans/FastCGI)

* [nginx优化之request_time和upstream_response_time差别](https://www.cnblogs.com/dongruiha/p/7007801.html)

>1、request_time
>
>官网描述：request processing time in seconds with a milliseconds resolution; time elapsed between the first bytes were read from the client and the log write after the last bytes were sent to the client 。
>
>指的就是从接受用户请求的第一个字节到发送完响应数据的时间，即包括接收请求数据时间、程序响应时间、输出响应数据时间。
>
>2、upstream_response_time
>
>官网描述：keeps times of responses obtained from upstream servers; times are kept in seconds with a milliseconds resolution. Several response times are separated by commas and colons like addresses in the $upstream_addr variable
>
>是指从Nginx向后端（php-cgi)建立连接开始到接受完数据然后关闭连接为止的时间。
>
>从上面的描述可以看出，$request_time肯定大于等于$upstream_response_time，特别是使用POST方式传递参数时，因为Nginx会把request body缓存住，接受完毕后才会把数据一起发给后端。所以如果用户网络较差，或者传递数据较大时，$request_time会比$upstream_response_time大很多。 
>
>所以如果使用nginx的accesslog查看php程序中哪些接口比较慢的话，记得在log_format中加入$upstream_response_time。
>
>根据引贴对官网描述的翻译：
>upstream_response_time:从 Nginx 建立连接 到 接收完数据并关闭连接
>request_time:从 接受用户请求的第一个字节 到 发送完响应数据.

## [logback 配置详解—logger、root](https://blog.csdn.net/u012129558/article/details/79947477)

>第2种：带有loger的配置，不指定级别，不指定appender，
>
>```java
>package logback;  
>  
>import org.slf4j.Logger;  
>import org.slf4j.LoggerFactory;  
>  
>public class LogbackDemo {  
>    private static Logger log = LoggerFactory.getLogger(LogbackDemo.class);  
>    public static void main(String[] args) {  
>        log.trace("======trace");  
>        log.debug("======debug");  
>        log.info("======info");  
>        log.warn("======warn");  
>        log.error("======error");  
>    }  
>}
>```
>
>
>
>```xml
> <configuration>   
>   
>  <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">   
>    <!-- encoder 默认配置为PatternLayoutEncoder -->   
>    <encoder>   
>      <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>   
>    </encoder>   
>  </appender>   
>   
>  <!-- logback为java中的包 -->   
>  <logger name="logback"/>   
>   
>  <root level="DEBUG">             
>    <appender-ref ref="STDOUT" />   
>  </root>     
>     
> </configuration>
>```
>
>其中appender的配置表示打印到控制台(稍后详细讲解appender )；
>
>**<logger name="logback" />将控制logback包下的所有类的日志的打印，但是并没用设置打印级别，所以继承他的上级<root>的日志级别“DEBUG”；
>没有设置addtivity，默认为true，将此loger的打印信息向上级传递；
>没有设置appender，此loger本身不打印任何信息。
><root level="DEBUG">将root的打印级别设置为“DEBUG”，指定了名字为“STDOUT”的appender.**
>
>**当执行logback.LogbackDemo类的main方法时， 因为LogbackDemo 在包logback中，所以首先执行<logger name="logback" />，将级别为“DEBUG”及大于“DEBUG”的日志信息传递给root，本身并不打印;**

## 跨域专题     ###

什么是跨域？
因为浏览器的同源策略规定某域下的客户端在没明确授权的情况下，不能读写另一个域的资源。
而在实际开发中，前后端常常是相互分离的，并且前后端的项目部署也常常不在一个服务器内或者在一个服务器的不同端口下。前端想要获取后端的数据，就必须发起请求，如果不做一些处理，就会受到浏览器同源策略的约束。后端可以收到请求并返回数据，但是前端无法收到数据。
为何浏览器会制定同源策略
同源（同协议、同域名、同端口）

如果在A网站中，我们希望使用Ajax来获得B网站中的特定内容
如果A网站与B网站不在同一个域中，那么就出现了跨域访问问题。
CSRF（Cross-site request forgery），中文名称：跨站请求伪造。
Cross Origin Resource Share (CORS)
CORS是一个跨域资源共享方案，为了解决跨域问题，通过增加一系列请求头和响应头，规范安全地进行跨站数据传输。

* 客户端只需按规范设置请求头。
* 服务端按规范识别并返回对应响应头，或者安装相应插件，修改相应框架配置文件等。具体视服务端所用的语言和框架而定。

同源：
如果两个页面的协议、域名、端口都相同，则两个页面具有相同的源。
同源策略限制了从同一个源加载的文档或脚本如何与来自另一个源的资源进行交互。
跨域可以大概分为两种目的

* 前后端分离时，前端为了获取后端数据而跨域
* 为不同域下的前端页面通信而跨域

## XSS 注入专题     ###

XSS注入问题是如何处理的？
XSS(Cross Site Scripting)，即跨站脚本攻击，XSS 通过在用户端注入恶意的可运行脚本，若服务器端对用户输入不进行处理，直接将用户输入输出到浏览器，则浏览器将会执行用户注入的脚本。
XSS常见漏洞出现的地方：
　　数据交互的地方：
　　　　-get post cookies headers
　　　　-反馈与浏览
　　　　-富文本编辑器
　　　　-各类标签插入和自定义
　　数据输出的地方：
　　　　-用户资料
　　　　-关键词、标签、说明
　　　　-文件上传
XSS出现的原因？
　　在HTML中常用到字符实体，将常用到的字符实体没有进行转译，导致完整的标签出现，在可输入的文本框等某些区域内输入特定的某些标签导致代码被恶意篡改。

防御措施就是对任何用户提交到服务器上的文本都要经过编码或者转译。

验证码生成工具：
Kaptcha

## 机器学习     ####

GBDT，LR

-----------数据结构---------------------------

MQ的 exactly-once 阻塞队列。

## MQ专题      ####

* rabbitMQ 相关
  （6）.消息基于什么传输？
  由于TCP连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。
  RabbitMQ使用信道的方式来传输数据。信道是建立在真实的TCP连接内的虚拟连接，且每条TCP连接上的信道数量没有限制。
  （7）.消息如何分发？
  若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者（前提是消费者能够正常处理消息并进行确认）。
  通过路由可实现多消费的功能
  （9）.如何确保消息不丢失？
  **消息持久化，当然前提是队列必须持久化**
  RabbitMQ 确保持久性消息能从服务器重启中恢复的方式是，将它们写入磁盘上的一个持久化日志文件，当发布一条持久性消息到持久交换器上时，Rabbit 会在消息提交到日志文件后才发送响应。
  **一旦消费者从持久队列中消费了一条持久化消息，RabbitMQ会在持久化日志中把这条消息标记为等待垃圾收集**。如果持久化消息在被消费之前RabbitMQ重启，那么Rabbit会自动重建交换器和队列（以及绑定），
  并重新发布持久化日志文件中的消息到合适的队列。
  （10）mq好处
  （11）：为什么使用MQ?
  主要是：解耦、异步、削峰。
  （1）解耦：A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃......A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。
  就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦。
  （2）异步：A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求。如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms。
  （3）削峰：减少高峰时期对服务器压力。
  （12）详情服务的mq是用的fanout路由策略；fanout广播模式

* [MQ如何保证消息的可靠性传输（绝对通俗易懂）](https://blog.csdn.net/qq_32662795/article/details/88742397)

>## 面试题剖析
>
>数据的丢失问题，可能出现在**生产者、MQ、消费者**中，咱们从 RabbitMQ 和 Kafka 分别来分析一下吧。
>
>* **生产者弄丢了数据**
>
>生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。
>
>此时可以选择用 RabbitMQ 提供的事务功能，就是生产者**发送数据之前**开启 RabbitMQ 事务`channel.txSelect`，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务`channel.txRollback`，然后重试发送消息；如果收到了消息，那么可以提交事务`channel.txCommit`。
>
>``` java
>// 开启事务
>channel.txSelect
>try {
>    // 这里发送消息
>} catch (Exception e) {
>    channel.txRollback
> 
>    // 这里再次重发这条消息
>}
> 
>// 提交事务
>channel.txCommit
>```
>
>但是问题是，RabbitMQ 事务机制（同步）一搞，基本上**吞吐量会下来，因为太耗性能**。
>
>所以一般来说，如果你要确保说**写 RabbitMQ 的消息别丢，可以开启 `confirm` 模式，在生产者那里设置开启 `confirm` 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 `ack` 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 `nack` 接口，告诉你这个消息接收失败，你可以重试**。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。
>
>事务机制和 `confirm` 机制最大的不同在于，**事务机制是同步的**，你提交一个事务之后会**阻塞**在那儿，但是 `confirm` 机制是**异步**的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。
>
>所以一般在生产者这块**避免数据丢失**，都是用 `confirm` 机制的。
>
>* **RabbitMQ 弄丢了数据**
>
>就是 RabbitMQ 自己弄丢了数据，这个你必须**开启 RabbitMQ 的持久化**，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，**恢复之后会自动读取之前存储的数据**，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，**可能导致少量数据丢失**，但是这个概率较小。
>
>设置持久化有**两个步骤**：
>
>- 创建 queue 的时候将其设置为持久化 这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。
>- 第二个是发送消息的时候将消息的 `deliveryMode` 设置为 2
>  就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。
>
>必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。
>
>注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。
>
>所以，持久化可以跟生产者那边的 `confirm` 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 `ack` 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 `ack`，你也是可以自己重发的。
>
>* **消费端弄丢了数据**
>
>RabbitMQ 如果丢失了数据，主要是因为你消费的时候，**刚消费到，还没处理，结果进程挂了**，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。
>
>这个时候得用 RabbitMQ 提供的 `ack` 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 `ack`，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 `ack` 一把。这样的话，如果你还没处理完，不就没有 `ack` 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。

### [OpenMessaging概述](http://dazhuanlan.com/2020/01/30/5e328b5fd5f5d/)

>## 领域架构
>
>![image-20210607121958613](fj问题及知识点记录.assets/image-20210607121958613.png)
>
>上图展示了OpenMessaging的领域架构。可见不同于普通仅提供管道和存储功能的消息队列，OpenMessaging还具备转换数据的能力(Routing)，并且不像Kafka作为附加组件的Streams，OpenMessaging的Routing更多是原生架构的一部分，地位更高。下面逐一解释图中涉及的实体。
>
>### NameSpace
>
>NameSpace类似于Linux的cgroup，用于安全地对资源进行隔离。每个NameSpace下都有自己的一组producer, consumer, topic, queue等等。
>
>### Producer
>
>OpenMessaging提供两种Producer:
>
>- 普通Producer，为延迟优化，提供多种方法来将消息流式地发送到Topic或者Queue，但是specification并没有进一步描述具体有什么方法，只能拭目以待。
>- SequenceProducer，为吞吐量优化，可以将多条消息合并为一个batch再发送给下游。
>
>看起来两种producer并没有什么质的差别，或许最关键的点在于发送方法上的不同。
>
>### Consumer
>
>不同于有固定消息模式的消息队列，OpenMessaging提供推、拉和流三种消息模式，分别对应三种consumer:
>
>- PullConsumer，从指定queue拉取消息，可以在任何时候通过消息确认机制提交消费结果。一个PullConsumer只能从一个指定的queue拉取消息。
>- PushConsumer，可以从多个queue接受消息，消息是以推的方式从服务端发送过来。PushConsumer可以通过不同的MessageListener来连接多个queue，然后在任何时间通过ReceiveMessageContext来条消费结果。
>- StreamingConsumer，一个面向流的consumer，可以很容易地和流式计算/大数据相关的平台集成。StreamingConsumer支持从指定queue像迭代器一样逐条消费消息。
>
>### Topic， Queue和Routing
>
>这三个实体有很强的联系，尽管Topic和Queue的作用不同，人们有可能会将它搞混。
>
>#### Topic
>
>Topic用于存储原始数据，服务端接收到的消息首先会被存放到这里。对于topic是否对消息的分布和顺序提供保证，OpenMessaging未作出要求。
>
>#### Routing
>
>在topic里面的消息是原始未经处理的，这并不能被consumer直接使用。换句话讲，topic是面向producer的，而不是面向consumer。Routing负责对topic里的消息进行处理，并路由到合适的queue。每个Routing拥有一个operator pipeline，后者由一系列的operator组成。消息经过这个pipeline从topic流向queue。 类似于流计算的一个转换函数，operator代表了对数据进行处理的操作。operator的种类有表达式operator(估计和lambda相似)，deduplicatot operator(用于去重)，joiner operator，filter operator, rpc operator等等。 最后，Routing可以跨网络传输，即通过建立多个routing实例将消息从一个网络发往另外一个网络。
>
>#### Queue
>
>消息被路由到queue之后，consumer就可以进行消费了。值得注意的是，Queue是分区的，分区键是消息header的`SHARDING_KEY`。Queue也可以从producer直接接收消息，即在数据流中跳过Topic和Routing，这样的话延迟更低，适合不需要对消息进行转换的场景。





------------



## PRC 专题     ####

* 既然有 HTTP 请求，为什么还要用 RPC 调用？

>我估计题主是看了下面这个图，觉得http和rpc是在同一个层，而且互斥的概念。**RPC只是对底层协议的封装，其实对具体的通信协议是啥并没有太多要求**。
>
>![img](./img/20200526_rpc_http_001.jpg?lastModify=1590476919)
>
>其实**http是最常用的承载RPC的通信协议之一。而且我们可以在http 上传输xml和json这样的文本协议，也可以是protobuf和thrift这样的二进制协议，这都不是问题。大家常用的REST api就可以很好的封装成rpc。**当然，http这种协议是笨重一些，但它的穿透性比较好，配套的设施也齐全，也比较简单直观，还是比较收欢迎的。**比如说著名的grpc就通过http来传输。**
>
>至于题主说引用太多包的问题，这就是RPC的服务器端框架和实现的问题了。要看题主要用什么样的框架，但总的来说这些rpc框架是让你的远程调用更方便，而不是更麻烦的。

既然有 HTTP 请求，为什么还要用 RPC 调用？ - 手不要乱摸的回答 - 知乎 https://www.zhihu.com/question/41609070/answer/191965937

>这个问题其实是有理解误区的，首先 http 和 rpc 并不是一个并行概念。
>
>rpc 是远端过程调用，**其调用协议通常包含传输协议和序列化协议。**
>
>传输协议包含: 如著名的 [gRPC]([grpc / grpc.io](https://link.zhihu.com/?target=http%3A//www.grpc.io/)) 使用的 http2 协议，也有如dubbo一类的自定义报文的tcp协议。
>
>序列化协议包含: 如基于文本编码的 xml json，也有二进制编码的 protobuf hessian等。
>
>要解决这个问题就应该搞清楚 http 使用的 tcp 协议，和我们自定义的 tcp 协议在报文上的区别。
>
>**首先要否认一点 http 协议相较于自定义tcp报文协议，增加的开销在于连接的建立与断开。http协议是支持连接池复用的，也就是建立一定数量的连接不断开，并不会频繁的创建和销毁连接**。第二要说的是**http也可以使用protobuf这种二进制编码协议对内容进行编码**，因此二者最大的区别还是在传输协议上。
>
>通用定义的http1.1协议的tcp报文包含太多废信息，一个POST协议的格式大致如下：
>
>``` html
>HTTP/1.0 200 OK 
>Content-Type: text/plain
>Content-Length: 137582
>Expires: Thu, 05 Dec 1997 16:00:00 GMT
>Last-Modified: Wed, 5 August 1996 15:55:28 GMT
>Server: Apache 0.84
>
><html>
>  <body>Hello World</body>
></html>
>```
>
>即使编码协议也就是body是使用二进制编码协议，报文元数据也就是header头的键值对却用了文本编码，非常占字节数。如上图所使用的报文中有效字节数仅仅占约 30%，也就是70%的时间用于传输元数据废编码。
>
>**简单来说成熟的rpc库相对http容器，更多的是封装了“服务发现”，"负载均衡"，“熔断降级”一类面向服务的高级特性。可以这么理解，rpc框架是面向服务的更高级的封装。**如果把一个http servlet容器上封装一层服务发现和函数代理调用，那它就已经可以做一个rpc框架了。
>
>所以为什么要用rpc调用？
>
>**因为良好的rpc调用是面向服务的封装，针对服务的可用性和效率等都做了优化。单纯使用http调用则缺少了这些特性。**

区分 RPC 和 http：

RPC, Remote Procedure Call. 是相对于Local Procedure Call的。核心是能像使用local procedure那样，去调用remote procedure。性能优先的，会考虑基于TCP/UDP层，设计binary格式的协议。开发友好的，会选择基于HTTP协议实现text based的协议。

## 线程专题     ####

Java线程的生命周期

>在线程的生命周期中，它要经过 **新建（New）、就绪（Runnable）、运行（Running）、阻塞（Blocked）和死亡（Dead）5种状态**。尤其是当线程启动以后，它不可能一直"霸占"着CPU独自运行，所以CPU需要在多条线程之间切换，于是 **线程状态也会多次在运行、阻塞之间切换**。
>
>作者：猿码道
>链接：https://juejin.im/post/5a72d4bd518825735300f37b
>来源：掘金
>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

* [定时任务类ScheduledThreadPoolExecutor和心跳的使用](https://blog.csdn.net/genffe880915/article/details/101759261)

* [使用ThreadPoolExecutor进行多线程编程](https://www.cnblogs.com/fpqi/p/9719874.html)

>一旦程序启动将无限制执行下去，实际中可以通过限制定时任务的次数或者时间来终止程序的执行。
>
>1，限制程序执行的时间：scheduled.awaitTermination(100,TimeUnit.SECONDS); 这句话表明100毫秒后程序终止。
>
>2，限制程序执行的次数：如果是单线程，那么可以直接定义一个静态变量count，每执行一次，count加一，如果count大于某个值就调用shutdown或者shutdownNow函数；如果是多线程，稍微要复杂一点，但是原理也是一样的。定义一个静态变量count，没执行一个也是count加一，只不过在执行加一操作之前需要加锁，执行完之后需要解锁。

* [Java定时任务以及ScheduledThreadPoolExecutor需要注意的问题](https://blog.csdn.net/xfxf996/article/details/80876335)

>Java提供Timer和ScheduledThreadPoolExecutor两个类实现定时任务，其中Timer简单易用，但所有任务都是由同一个线程来调度，任务串行执行，任务之间存在互相干扰，一是前一个任务的延迟会导致后面的任务延迟，二是前一个任务异常导致后面的任务不再执行，三是Timer执行周期任务时依赖系统时间，如果当前系统时间发生变化，执行行为也会出现变化。
>
>  \1. 一定要使用try{}catch(Throwable t){}捕获所有可能的异常，因为ScheduledThreadPoolExecutor会在任务执行遇到异常时取消后续执行。
>
>  \2. 注意scheduleAtFixedRate与scheduleWithFixedDelay的区别，scheduleAtFixedRate是上一个任务开始执行之后延迟设定时间再执行，是从上一个任务开始时计时，但对于运行时长超过延迟时长的任务，会等上一个任务执行完之后，下一个任务才开始执行，此时，延时没有任何意义。而scheduleWithFixedDelay是在上一个任务结束执行之后延迟设定时间再执行，是从上一个任务结束时开始计算。

* [并发系列（7）之 ScheduledThreadPoolExecutor 详解](https://www.cnblogs.com/sanzao/p/10760641.html)



### FutureTask

futureTask 用法
https://www.cnblogs.com/yanliang12138/p/9798654.html

FutureTask 详解

https://blog.csdn.net/qq_39654841/article/details/90631795

>FutureTask介绍
>一个可取消的异步计算。FutureTask提供了对Future的基本实现，可以调用方法去开始和取消一个计算，可以查询计算是否完成并且获取计算结果。只有当计算完成时才能获取到计算结果，一旦计算完成，计算将不能被重启或者被取消，除非调用runAndReset方法。
>除了实现了Future接口以外，FutureTask还实现了Runnable接口，因此FutureTask交由Executor执行，也可以直接用线程调用执行(futureTask.run())。根据FutureTask的run方法执行的时机，FutureTask可以处于以下三种执行状态：
>1、未启动：在FutureTask.run()还没执行之前，FutureTask处于未启动状态。当创建一个FutureTask对象，并且run()方法未执行之前，FutureTask处于未启动状态。
>2、已启动：FutureTask对象的run方法启动并执行的过程中，FutureTask处于已启动状态。
>3、已完成：FutureTask正常执行结束，或者FutureTask执行被取消(FutureTask对象cancel方法)，或者FutureTask对象run方法执行抛出异常而导致中断而结束，FutureTask都处于已完成状态。
>FutureTask状态迁移图
>
>![image-20210705114356033](fj问题及知识点记录.assets/image-20210705114356033.png)
>
>当FutureTask处于未启动或者已启动的状态时，调用FutureTask对象的get方法会将导致调用线程阻塞。当FutureTask处于已完成的状态时，调用FutureTask的get方法会立即放回调用结果或者抛出异常。
>当FutureTask处于未启动状态时，调用FutureTask对象的cancel方法将导致线程永远不会被执行；当FutureTask处于已启动状态时，调用FutureTask对象cancel(true)方法将以中断执行此任务的线程的方式来试图停止此任务;当FutureTask处于已启动状态时，调用FutureTask对象cancel(false)方法将不会对正在进行的任务产生任何影响；当FutureTask处于已完成状态时，调用FutureTask对象cancel方法将返回false；
>FutureTask的get和cancel的执行示意图
>
>![image-20210705114415273](fj问题及知识点记录.assets/image-20210705114415273.png)

[关于java线程池的研究-Future与FutureTask](https://blog.csdn.net/chaofanwei/article/details/17300401)

___________



## 分布式事务

[关于分布式事务，XA协议的学习笔记](https://www.cnblogs.com/monkeyblog/p/10449363.html)



## 算法专题     ####

* **树型结构**
* [**MySQL索引背后的数据结构及算法原理**](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)

>### 局部性原理与磁盘预读
>
>由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，**要尽量减少磁盘I/O**。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：
>
>**当一个数据被用到时，其附近的数据也通常会马上被使用。**
>
>**程序运行期间所需要的数据通常比较集中。**
>
>**由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。**
>
>**预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。**当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。
>
>### B-/+Tree索引的性能分析
>
>到这里终于可以分析B-/+Tree索引的性能了。
>
>上文说过一般使用磁盘I/O次数评价索引结构的优劣。**先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点(h 表示树的高度)。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。**为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：
>
>**每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。**
>
>B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为(根据树的结构理解这个公式)
>
>![image-20210311224253874](./fj问题及知识点记录.assets/image-20210311224253874.png)
>
>![image-20210311224424465](./fj问题及知识点记录.assets/image-20210311224424465.png)
>
>O(h)=O(log d N)  。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。
>
>综上所述，用B-Tree作为索引结构效率是非常高的。
>
>而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。
>
>上文还说过，B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小：
>
>dmax=floor(pagesize/(keysize+datasize+pointsize))
>
>**floor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。**
>
>这一章从理论角度讨论了与索引相关的数据结构与算法问题，下一章将讨论B+Tree是如何具体实现为MySQL中索引，同时将结合MyISAM和InnDB存储引擎介绍非聚集索引和聚集索引两种不同的索引实现形式。
>
>

* [**从2-3树理解红黑树**](https://juejin.im/post/5c540e2ff265da2db155ee57)

1. B树

B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。那么B-Tree是满足下列条件的数据结构：

d为大于1的一个正整数，称为B-Tree的度。

h为一个正整数，称为B-Tree的高度。

每个非叶子节点由n-1个key和n个指针组成，其中d<=n<=2d。

每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。

所有叶节点具有相同的深度，等于树高h。

key和指针互相间隔，节点两端是指针。

一个节点中的key从左到右非递减排列。

所有节点组成树结构。

每个指针要么为null，要么指向另外一个节点。

如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于v(key1)v(key1)，其中v(key1)v(key1)为node的第一个key的值。

如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于v(keym)v(keym)，其中v(keym)v(keym)为node的最后一个key的值。

如果某个指针在节点node的左右相邻key分别是keyikeyi和keyi+1keyi+1且不为null，则其指向节点的所有key小于v(keyi+1)v(keyi+1)且大于v(keyi)v(keyi)。

图2是一个d=2的B-Tree示意图。

![](./img/20200603_b_tree.png)

2. **B+树**

B-Tree有许多变种，其中最常见的是B+Tree，例如MySQL就普遍使用B+Tree实现其索引结构。

与B-Tree相比，B+Tree有以下不同点：

每个节点的指针上限为2d而不是2d+1。

内节点不存储data，只存储key；叶子节点不存储指针。

![](./img/20200603_b_plus_tree.png)

一般来说，B+Tree比B-Tree更适合实现外存储索引结构，具体原因与外存储器原理及计算机存取原理有关.

**一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。**

![](./img/20200603_b_plus_tree2.png)

3. **二三树、红黑树** 

   https://juejin.im/post/5c540e2ff265da2db155ee57

2-3树的意思就是说，**一个父节点可以有两个子节点，也可以有三个子节点**，并且其也满足类似`二叉搜索树`的定义（父节点的值大于左子树，但小于右子树），所有叶子节点都在同一层。

红黑树也是一种**二叉平衡树**，它满足如下几个特性（根据算法中的定义）：

1. 根节点是黑色的。
2. 红链接均为左链接。
3. 从任一节点到其可达叶子节点，经过的黑色节点数量一样（黑平衡）。
4. 没有任何一个节点同时与两个红链接相连。

这个定义可能跟我们平常看到的不太一样，由于是以2-3树来理解红黑树，定义红链在左边，这样才能跟2-3树完全对应上。

`AVL`是一种极度平衡的二叉树，那为什么不用AVL呢？因为`AVL`插入删除要保持平衡，相比红黑树要慢一些，需要左旋右旋等等。但实际上它的旋转也只是几个场景的套用，哪些场景需要怎么旋转，理解就行了。

而**红黑树是近似平衡的（黑平衡），也就是说它不像`AVL`那样绝对的平衡，所以添加/删除节点后的平衡操作没那么多。所以对于插入和删除操作较多的场景，用红黑树效率会高一些**。

**将2-3树转换成红黑树**

主要思想：3节点分裂成2节点。

>将3节点的第一个元素，作为第二个元素的左节点，并用红色的线连接，此时红色线连接的节点就相当于红色。

![](./img/20200603_red_black_01.png)

将2-3树按照以上思想转换后，就得到了一颗红黑树。用这种方式理解是不是简单多了呢？

同时也有几个问题值得我们思考：

1. 为什么红链规定在左边呢？

   我觉得是前人的一个约定，为了保持统一，简化处理，都放在左边。那都放右边是不是也可以呢？

2. 没有任何一个节点同时与两个红链接相连

   因为一个红链表示一个3节点，如果有2个红链相连，则表示为4节点，不符合2-3树定义。

3. 根节点为黑色

   只有3节点的左链才为红色。根节点没有父节点，不可能为红色。

4. 根节点到叶子节点经过的黑色节点数目相同

   因为2-3树是完美平衡的。红黑树中经过的黑节点数=其层数。

   作者：summer_liu_liu
   链接：https://juejin.im/post/5c540e2ff265da2db155ee57
   来源：掘金
   著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

### 红黑树的应用

1. 散列表的冲突处理

   map的实现，底层一般会采用红黑树，在节点多的时候效率高。 在节点少的时候，可用链表方式。

2. 动态插入、删除和查询较多的场景

### [PriorityQueue详解](https://www.jianshu.com/p/f1fd9b82cb72)





## python专题     ###

### python数据类型
​    Numbers（数字）
​    String（字符串）
​    List（列表）
​    Tuple（元组）
​    Dictionary（字典）

### [Python内置的HTTP协议服务器SimpleHTTPServer使用指南](https://blog.51cto.com/tenderrain/1980603)

>Python内置了一个简单的HTTP服务器，只需要在命令行下面敲一行命令，一个HTTP服务器就起来了：
>
>```python
>python -m SimpleHTTPServer 80
>```
>
>如果当前文件夹有index.html文件，会默认显示该文件，否则，会以文件列表的形式显示目录下所有文件。这样已经实现了最基本的文件分享的目的，你可以做成一个脚本，再建立一个快捷方式，就可以很方便的启动文件分享了。

## Docker 专题   ###

[Dockerfile 中的Volume有什么意义，光用docker run -v效果相同吗？](https://segmentfault.com/q/1010000004107293)

>你可以把VOLUME理解为，从镜像中复制指定卷的文件夹到本地`/var/lib/docker/volumes/xxxxxxxxx/文件夹`，然后把本地的该文件夹挂载到容器里面去。
>
>本质上还是相当于一个本地文件夹挂载而已。
>
>继续补充，因为VOLUME实际上就是在本地新建了一个文件夹挂载了，那么实际上容器内部的文件夹有三种情况：
>1、没有指定VOLUME也没有指定-v，这种是普通文件夹。
>2、指定了VOLUME没有指定-v，这种文件夹可以在不同容器之间共享，但是无法在本地修改。
>3、指定了-v的文件夹，这种文件夹可以在不同容器之间共享，且可以在本地修改。
>
>首先，我们先了解容器中获取动态数据的方式：
>1、本地提供，挂载到容器
>2、远程提供，从远程下载
>3、生成提供，在容器内部生成
>
>后面两种命令都不需要在本地修改，但是他们生成的动态数据却可能需要共享。
>下载命令，比如git clone直接从git服务器拉取代码，不需要挂载本地文件夹。

* [关于Docker目录挂载的总结](https://www.cnblogs.com/ivictor/p/4834864.html)

docker 挂载多个主机文件夹作为数据卷,挂载几个主机目录就用几个-v选项。

   `docker run -it -P --name v_test -v /home/amor/Documents/:/opt/web_doc -v /home/amor/Downloads/:/opt/web_down centos /bin/bash`

* [如何运行多进程Docker容器？](http://dockone.io/article/951)

>一种方法是使用**Shell脚本**，另一种方法是使用进程管理工具[Supervisor](http://supervisord.org/)。

* [ubuntu中supervisor的安装及配置](https://www.jianshu.com/p/68605ac9d06a)

* [docker开机启动nginx，mysql等服务的方式](https://blog.csdn.net/u013945470/article/details/85268286)

>注意！注意！注意！
>
>所有supervisor管理的进程都不能开启后台模式，例如"service nginx start"这种，只能使用前台模式进行配置，否则服务会一直重启！

* [Docker容器时间与宿主机时间不同步](https://blog.csdn.net/lin521lh/article/details/78349739)

>统一两者的时区有下面几种方法
>1、共享主机的localtime
>
>#创建容器的时候指定启动参数，挂载localtime文件到容器内，保证两者所采用的时区是一致的。
>docker run -it -d --name web -v /etc/localtime:/etc/localtime:ro  centos:1.0  /bin/bash
>2、复制主机的localtime
>
>docker cp /etc/localtime 753f856bca45:/etc/
>3、创建dockerfile文件的时，自定义该镜像的时间格式及时区。在dockerfile文件里添加下面内容：
>#设置时区
>RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && echo 'Asia/Shanghai' >/etc/timezone
>————————————————
>版权声明：本文为CSDN博主「VacantYang」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
>原文链接：https://blog.csdn.net/lin521lh/article/details/78349739

[docker mac 命令行登录报错处理 : Error saving credentials: error storing credentials - err: exit status 1](https://blog.csdn.net/xufwind/article/details/88756557?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param)

>在网上找了很久，总算找个一个能用的:以下为具体操作
>
>\1. 点开启动台，搜索 Keychain Access并点开, 或是点开 访达(findder) -> 应用程序(applications) -> 实用工具(utilities) ->钥匙串访问(Keychain Access)
>
>\2. 右键点击登录 -> 锁定钥匙串登录，再解锁钥匙串登录就可以了，注意解锁的时候需要输入mac登录密码
>
>
>
>知识背景参考：
>
>https://docs.docker.com/engine/reference/commandline/login/#credentials-store

### ENTRYPOINT 指令

类似于 CMD 指令，但其不会被 docker run 的命令行参数指定的指令所覆盖，**而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序。所以 Dockerfile 中使用了ENTRYPOINT指令后使用命令行 docker run 加参数时要慎重，会直接加到 ENTRYPOINT 指令指定的程序后面。**

但是, 如果运行 docker run 时使用了 --entrypoint 选项，此选项的参数可当作要运行的程序覆盖 ENTRYPOINT 指令指定的程序。

[docker 安装](https://yeasy.gitbook.io/docker_practice/install/mac)

##  ###

# Netty 专题

## [Netty的高低水位](https://zhuanlan.zhihu.com/p/272840446)

>假如我们的底层使用Netty作为网络通信框架,业务流程在将业务数据发送到对端之前,实际先要将发送到Netty的缓冲区中,然后再从Netty的缓冲区发送到TCP的缓冲区,最后再到对端.
>
>![img](fj问题及知识点记录.assets/v2-c67cf9acd2a79444d013a007904a783c_720w.jpg)
>
>业务数据不可能无限制向Netty缓冲区写入数据,TCP缓冲区也不可能无限制写入数据.Netty通过高低水位控制向Netty缓冲区写入数据的多少.
>
>它的大体流程就是向Netty缓冲区写入数据的时候,会判断写入的数据总量是否超过了设置的高水位值,如果超过了就设置通道(Channel)不可写状态.
>
>当Netty缓冲区中的数据写入到TCP缓冲区之后,Netty缓冲区的数据量变少,当低于低水位值的时候,就设置通过(Channel)可写状态.

## 池化技术

理解 httpClientPool，jdcp Pool，Apache commons-pool2。

### [Apache commons-pool2-2.4.2源码学习笔记](https://blog.csdn.net/zilong_zilong/article/details/78556281)

>-  **PooledObjectFactory/KeyedPooledObjectFactory**：是两个**接口，作用都是产生PooledObject的工厂**，定义了如何makeObject创建、destroyObject销毁、validateObject校验、activateObject激活PooledObject对象，**使用Apache commons-pool2的使用者需要自己实现这个接口**
>-  **PooledObject**：是一个**接口**，定义了getCreateTime获取PooledObject创建时间，getActiveTimeMillis获取PooledObject处于激活状态的时间，getIdleTimeMillis获取PooledObject空闲时间，getLastBorrowTime获取PooledObject最近借出时间，getLastReturnTime获取PooledObject最近归还时间，getLastUsedTime获取PooledObject最近使用时间。**目前Apache commons-pool2提供了2个默认实现DefaultPooledObject和PooledSoftReference，一般使用DefaultPooledObject即可**
>-  **ObjectPool/KeyedObjectPool**：是两个**接口，作用都是管理池里面的PooledObject**，borrowObject借出PooledObject，returnObject归还PooledObject，invalidateObject调用PooledObjectFactory销毁PooledObject，addObject调用PooledObjectFactory创建PooledObject，getNumIdle给出PooledObject空闲个数，getNumActive给出PooledObject激活的个数，**使用Apache commons-pool2的使用者可以使用默认的5个实现(SoftReferenceObjectPool GenericObjectPool ProxiedObjectPool GenericKeyedObjectPool ProxiedKeyedObjectPool)，也可以自己实现**
>
>对象池的原理都差不多，基本一通全通，可以针对性的去阅读你常用的对象池（数据库连接池、HTTPclient连接池等等）源代码，对自己来说是一种技能升华。

### [轻量级的对象池](https://www.iteye.com/blog/cywhoyi-1954393) 该篇文章重要性在于提供了自己实现一个轻量级对象池的思路

>运用的场景：
>
>* 高频率的运用同一的资源
>
>* 对象大且很消耗内存（DB连接）
>
>* 需要长时间的初始化
>
>* IO消耗大
>
>* 对象非线程安全
>
>Apache Commons Pool 提供其轻量级的作用，不过它并未使用JDK1.5之后的Execute的框架，这是我觉得可能比较可惜的，就如同Proxool跟Boncp比较，性能指标提升最大一个就是分区和使用Execute、Guava等性能提升比较大的工具包。
>
>```java
>import java.util.concurrent.ConcurrentLinkedQueue;  
>import java.util.concurrent.Executors;  
>import java.util.concurrent.ScheduledExecutorService;  
>import java.util.concurrent.TimeUnit;  
>  
>public abstract class ObjectPool<T> {  
>    private ConcurrentLinkedQueue<T> pool;  
>  
>    private ScheduledExecutorService executorService;  
>  
>    /** 
>     * Creates the pool. 
>     *  
>     * @param minIdle 
>     *            初始化最小的对象池中对象创建数量 
>     */  
>    public ObjectPool(final int minIdle) {  
>        // initialize pool  
>        initialize(minIdle);  
>    }  
>  
>    /** 
>     * Pool创建 
>     *  
>     * @param minIdle 
>     *            最小的数量 
>     * @param maxIdle 
>     *            最大数量 
>     * @param validationInterval 
>     *            检查最大/最小的池中的对象的频率 
>     */  
>    public ObjectPool(final int minIdle, final int maxIdle,  
>            final long validationInterval) {  
>        // initialize pool  
>        initialize(minIdle);  
>  
>        // check pool conditions in a separate thread  
>        executorService = Executors.newSingleThreadScheduledExecutor();  
>        executorService.scheduleWithFixedDelay(new Runnable() {  
>            @Override  
>            public void run() {  
>                int size = pool.size();  
>                if (size < minIdle) {  
>                    int sizeToBeAdded = minIdle - size;  
>                    for (int i = 0; i < sizeToBeAdded; i++) {  
>                        pool.add(createObject());  
>                    }  
>                } else if (size > maxIdle) {  
>                    int sizeToBeRemoved = size - maxIdle;  
>                    for (int i = 0; i < sizeToBeRemoved; i++) {  
>                        pool.poll();  
>                    }  
>                }  
>            }  
>        }, validationInterval, validationInterval, TimeUnit.SECONDS);  
>    }  
>  
>    /** 
>     * 获取对象，如果没有，那就创建且返回 
>     *  
>     * @return T borrowed object 
>     */  
>    public T borrowObject() {  
>        T object;  
>        if ((object = pool.poll()) == null) {  
>            object = createObject();  
>        }  
>  
>        return object;  
>    }  
>  
>    /** 
>     * Returns object back to the pool. 
>     *  
>     * @param object 
>     *            object to be returned 
>     */  
>    public void returnObject(T object) {  
>        if (object == null) {  
>            return;  
>        }  
>  
>        this.pool.offer(object);  
>    }  
>  
>    /** 
>     * Shutdown this pool. 
>     */  
>    public void shutdown() {  
>        if (executorService != null) {  
>            executorService.shutdown();  
>        }  
>    }  
>  
>    /** 
>     * Creates a new object. 
>     *  
>     * @return T new object 
>     */  
>    protected abstract T createObject();  
>  
>    private void initialize(final int minIdle) {  
>        pool = new ConcurrentLinkedQueue<T>();  
>  
>        for (int i = 0; i < minIdle; i++) {  
>            pool.add(createObject());  
>        }  
>    }  
>}  
>```
>
>

## java 并发包中的容器

#### CopyOnWriteArrayList 

[CopyOnWriteArrayList应用场景](https://www.cnblogs.com/zz-ksw/p/12774371.html)

>### 适用场景
>
>#### 读操作可以尽可能的快，而写即使慢一些也没关系
>
>在很多应用场景中，读操作可能会远远多于写操作。比如，有些系统级别的信息，往往只需要加载或者修改很少的次数，但是会被系统内所有模块频繁的访问。对于这种场景，我们最希望看到的就是读操作可以尽可能的快，而写即使慢一些也没关系。
>
>#### 读多写少
>
>黑名单是最典型的场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单中，黑名单并不需要实时更新，可能每天晚上更新一次就可以了。当用户搜索时，会检查当前关键字在不在黑名单中，如果在，则提示不能搜索。这种读多写少的场景也很适合使用 CopyOnWrite 集合。
>
>### 读写规则
>
>#### 读写锁的规则
>
>读写锁的思想是：读读共享、其他都互斥（写写互斥、读写互斥、写读互斥），原因是由于读操作不会修改原有的数据，因此并发读并不会有安全问题；而写操作是危险的，所以当写操作发生时，不允许有读操作加入，也不允许第二个写线程加入。
>
>### 对读写锁规则的升级
>
>CopyOnWriteArrayList 的思想比读写锁的思想又更进一步。为了将读取的性能发挥到极致，CopyOnWriteArrayList **读取是完全不用加锁的**，更厉害的是，**写入也不会阻塞读取操作**，也就是说你可以在写入的同时进行读取，只有写入和写入之间需要进行同步，也就是不允许多个写入同时发生，但是在写入发生时允许读取同时发生。这样一来，读操作的性能就会大幅度提升。
>
>```java
> /**
>     * Appends the specified element to the end of this list.
>     *
>     * @param e element to be appended to this list
>     * @return {@code true} (as specified by {@link Collection#add})
>     */
>    public boolean add(E e) {
>        final ReentrantLock lock = this.lock;
>        lock.lock();
>        try {
>            Object[] elements = getArray();
>            int len = elements.length;
>            Object[] newElements = Arrays.copyOf(elements, len + 1);
>            newElements[len] = e;
>            setArray(newElements);
>            return true;
>        } finally {
>            lock.unlock();
>        }
>    }
>```
>
>#### 特点
>
>**CopyOnWrite的含义**
>
>从 CopyOnWriteArrayList 的名字就能看出它是满足 CopyOnWrite 的 ArrayList，CopyOnWrite 的意思是说，当容器需要被修改的时候，不直接修改当前容器，而是先将当前容器进行 Copy，复制出一个新的容器，然后修改新的容器，完成修改之后，再将原容器的引用指向新的容器。这样就完成了整个修改过程。

#### ConcurrentLinkedQueue

无锁的设计

##### Java并发编程之ConcurrentLinkedQueue详解 (java 并发编程的艺术  方腾飞 书中内容)

https://blog.csdn.net/qq_38293564/article/details/80798310



## java 实战



### [接口响应时间长的调优经验](https://www.jianshu.com/p/f386fdc50620)

># 解决方案
>
>## Version 1
>
>引入redis 缓存。
>
>为了提高接口的性能，并通过一步步的引入缓存、队列等中间件减少数据库的读请求和分离数据库的写请求，且对线程池的调优。
>
>## Version 2
>
>此版本接入了队列，**通过队列将数据库插入和修改操作在队列消费端操作**，**在接口中隔离了对数据库的操作**。
>
>引入队列后，博主以为接口应该不会超时了，虽然`数据库的数据量`比较大，CRUD比较慢，可接口中已经将写操作清零，读操作减少一大半。查询`nginx日志`发现超时尽管有所减少，但超时每秒还是有几百，总体每日平均超时为`5%`左右。
>
>## Version 3
>
>看下Java线程是否可以调优，目前系统使用的是Netty4作为容器，监听端口来响应；作了以下事情：
>
>1. 查看GC日志，配合[jstat命令](https://links.jianshu.com/go?to=http%3A%2F%2Fwww.tongtech.com%2Fupload_files%2Ffiles%2Fdoc%2F56.pdf)查询GC频率，是否出现频繁GC，或者Full GC次数过多等情况
>2. 查看线程日志，配合[jstack命令](https://links.jianshu.com/go?to=http%3A%2F%2Fwww.cnblogs.com%2Fchenpi%2Fp%2F5377445.html)分析是否出现线程死锁，Object.wait()情况
>3. 通过jdk自带的jmc工具观察堆内存使用情况；也可观察线程占用CPU百分比
>
>通过上面的三步操作，得到结果：
>
>- GC频率不高，Full GC几乎没有
>- 内存使用正常，尚未超过临界值
>- 通过jstack发现大量的线程处于WAITING状态，可是在jstack中尚未发现是哪个方法是引起WAITING的元凶
>
>于是去网上找资料，如何能定位某个方法的执行时间，找到了jdk自带的[jvisualvm工具](https://links.jianshu.com/go?to=https%3A%2F%2Fwww.ibm.com%2Fdeveloperworks%2Fcn%2Fjava%2Fj-lo-visualvm%2F)[Notes：jdk1.7u45后才自带有该工具，否则需要自行安装]
>
>打开jvisualvm->远程->添加JMX连接->抽样器->CPU->在CPU样例中点击快照
>
>**Notes:快照需要等一两分钟跑了数据后再进行生成，一般生成两三次快照进行观察对比。**

### [面对数据量大的情况如何进行优化？](https://www.zhihu.com/question/267560156)

### [阿里编码规范插件idea](https://github.com/alibaba/p3c/blob/master/idea-plugin/README_cn.md)

### [IntelliJ 创建main函数快捷](https://blog.csdn.net/tiantiandjava/article/details/42269173)

>提示可以CTRL + j 可以查看，mac系统下是  command＋j。

## LVS专题

[LVS介绍及工作原理图解](http://www.178linux.com/89580)

>二、LVS体系架构
>
>使用LVS架设的服务器集群系统有三个部分组成：最前端的负载均衡层（Loader Balancer），中间的服务器群组层，用Server Array表示，最底层的数据共享存储层，用Shared Storage表示。在用户看来所有的应用都是透明的，用户只是在使用一个虚拟服务器提供的高性能服务。
>
>LVS的各个层次的详细介绍：
>
>Load Balancer层：位于整个集群系统的最前端，有一台或者多台负载调度器（Director Server）组成，LVS模块就安装在Director Server上，而Director的主要作用类似于一个路由器，它含有完成LVS功能所设定的路由表，通过这些路由表把用户的请求分发给Server Array层的应用服务器（Real Server）上。同时，在Director Server上还要安装对Real Server服务的监控模块Ldirectord，此模块用于监测各个Real Server服务的健康状况。在Real Server不可用时把它从LVS路由表中剔除，恢复时重新加入。
>
>Server Array层：由一组实际运行应用服务的机器组成，Real Server可以是WEB服务器、MAIL服务器、FTP服务器、DNS服务器、视频服务器中的一个或者多个，每个Real Server之间通过高速的LAN或分布在各地的WAN相连接。在实际的应用中，Director Server也可以同时兼任Real Server的角色。
>
>Shared Storage层：是为所有Real Server提供共享存储空间和内容一致性的存储区域，在物理上，一般有磁盘阵列设备组成，为了提供内容的一致性，一般可以通过NFS网络文件系统共享数 据，但是NFS在繁忙的业务系统中，性能并不是很好，此时可以采用集群文件系统，例如Red hat的GFS文件系统，oracle提供的OCFS2文件系统等。
>
>从整个LVS结构可以看出，Director Server是整个LVS的核心，目前，用于Director Server的操作系统只能是Linux和FreeBSD，linux2.6内核不用任何设置就可以支持LVS功能，而FreeBSD作为 Director Server的应用还不是很多，性能也不是很好。对于Real Server，几乎可以是所有的系统平台，Linux、windows、Solaris、AIX、BSD系列都能很好的支持。

## 规范

### [RESTful API 设计指南](http://www.ruanyifeng.com/blog/2014/05/restful_api.html)



# typesafe config

## [配置文件神器 typesafe conf 用法简介](https://blog.csdn.net/weixin_34319374/article/details/91913624)



## [HOCON (Human-Optimized Config Object Notation) 说明文档](https://github.com/lightbend/config/blob/master/HOCON.md#config-object-merging-and-file-merging)

>### Duplicate keys and object merging
>
>The JSON spec does not clarify how duplicate keys in the same object should be handled. In HOCON, duplicate keys that appear later override those that appear earlier, unless both values are objects. If both values are objects, then the objects are merged.
>
>Note: this would make HOCON a non-superset of JSON if you assume that JSON requires duplicate keys to have a behavior. The assumption here is that duplicate keys are invalid JSON.
>
>To merge objects:
>
>- add fields present in only one of the two objects to the merged object.
>- for non-object-valued fields present in both objects, the field found in the second object must be used.
>- for object-valued fields present in both objects, the object values should be recursively merged according to these same rules.



# 实战-逻辑删除时的唯一约束

逻辑删除 唯一约束， 会导致虽然某条数据已经被删除，但是加了唯一约束的字段还是不能插入相同的数据？

### [逻辑删除和唯一索引](https://chsm1998.github.io/2020/08/29/logical-deletion-and-unique-index/)

**建立联合索引，is_deteled字段不要用单纯的0和1来表示，可以用0来表示正常数据，逻辑删除数据可以有以下几种方案来表示（推荐）**

1. 将删除标识的正常设为固定值,删除值使用叠加值(-1,-2,-3)**（该方案需保证字段值为全局递增或全局递减，分布式环境下实现复杂）**

2. **将删除标识的删除状态设为id（推荐，使用主键确保不会发生索引冲突，并且实现简单）**

   若使用的是mybatis-plus框架可将logic-delete-value设置为如下：（看 mybatis-plus 官网，更深入掌握？？）

   ```
   logic-delete-value: id
   ```

3. 将删除标识设为当前时间戳**（时间戳在极端情况下依旧有索引冲突的风险）**

   若使用的是mybatis-plus框架可将logic-delete-value设置为如下：

   ```
   logic-delete-value: REPLACE(unix_timestamp(current_timestamp(3)),'.','')
   ```

# [TCP协议中的三次握手和四次挥手(图解)](https://blog.csdn.net/whuslei/article/details/6667471)

>![image-20210705210531631](fj问题及知识点记录.assets/image-20210705210531631.png)
>
>

# [logger.isDebugEnabled()的作用](https://blog.csdn.net/broucetrong/article/details/53505966)

>在项目中经常会看到这样的代码：
>
>```java
>if (logger.isDebugEnabled()) {
>    logger.debug(message);
>}
>```
>
>##### **为什么要这样做呢？**
>
>　　且看isDebugEnabled()的源码：
>
>```java
>public boolean isDebugEnabled() {    
>  if(repository.isDisabled( Level.DEBUG_INT))
>      return false;
>  return Level.DEBUG.isGreaterOrEqual(this.getEffectiveLevel());
>}
>```
>
>以下是debug()的源码：
>
>```java
>public void debug(Object message) {
>    if(repository.isDisabled(Level.DEBUG_INT))
>        return;
>    if(Level.DEBUG.isGreaterOrEqual(this.getEffectiveLevel())) {
>        forcedLog(FQCN, Level.DEBUG, message, null);
>    }
>}
>```
>
>可见，debug()中做了跟isDebugEnabled()几乎一样的判断，看起来直接调用debug()比先判断isDebugEnabled()更加效率。
>　　此时来看下面的代码：
>`logger.debug("The money is " + getTotalMoney());`
>
>　　假设我们的日志级别设置为info，debug()方法调用后会判断`if(repository.isDisabled(Level.DEBUG_INT))`，然后return。但是在调用debug()方法时，必须提供参数。要获得参数，就需要执行getTotalMoney()并拼接。假设这个获取参数的过程需要10秒钟，则系统会在花费10秒后决定return，这显然很得不偿失。
>　　加上logger.isDebugEnabled()判断，只会使写日志的时间增加大概万分之一，但是如果不加此判断，系统可能需要花费更多的时间，所以在大多数情况下，在输出debug日志前加上logger.isDebugEnabled()比较好。

# [Post 方法参数写在body中和写在url中有什么区别？](https://www.zhihu.com/question/64312188)

> 解释之前我们先基于Http协议,根据Http的请求方法对应的数据传输能力把Http请求分为Url类请求和Body类请求，Url类请求包括但不限于GET、HEAD、OPTIONS、TRACE 等请求方法。Body类请求包括但不限于POST、PUSH、PATCH、DELETE 等请求方法。
>
> ![image-20210712161341100](fj问题及知识点记录.assets/image-20210712161341100.png)
>
> **Body类请求除了可以把参数放到url中，也可以通过body发送数据。**
>
> ![image-20210712161405655](fj问题及知识点记录.assets/image-20210712161405655.png)



# [Curator Framework的基本使用方法](https://www.cnblogs.com/jun-ma/p/4918137.html)

# 跨站请求伪造

>**跨站请求伪造**（英语：Cross-site request forgery），也被称为 **one-click attack** 或者 **session riding**，通常缩写为 **CSRF** 或者 **XSRF**， 是一种挟制用户在当前已登录的Web[应用程序](https://baike.baidu.com/item/应用程序/5985445)上执行非本意的操作的攻击方法。跟[跨网站脚本](https://baike.baidu.com/item/跨网站脚本/23316003)（XSS）相比，**XSS** 利用的是用户对指定网站的信任，CSRF 利用的是[网站](https://baike.baidu.com/item/网站/155722)对用户[网页浏览器](https://baike.baidu.com/item/网页浏览器/8309940)的信任.
>
>假如一家银行用以运行转账操作的URL地址如下：http://www.examplebank.com/withdraw?account=AccoutName&amount=1000&for=PayeeName
>
>那么，一个恶意攻击者可以在另一个网站上放置如下代码： <img src="http://www.examplebank.com/withdraw?account=Alice&amount=1000&for=Badman">
>
>如果有账户名为Alice的用户访问了恶意站点，而她之前刚访问过银行不久，登录信息尚未过期，那么她就会损失1000资金。
>
>这种恶意的网址可以有很多种形式，藏身于网页中的许多地方。此外，攻击者也不需要控制放置恶意网址的网站。例如他可以将这种地址藏在论坛，博客等任何[用户生成内容](https://baike.baidu.com/item/用户生成内容)的网站中。这意味着**如果服务端没有合适的防御措施的话，用户即使访问熟悉的可信网站也有受攻击的危险**。
>
>透过例子能够看出，攻击者并不能通过CSRF攻击来直接获取用户的账户控制权，也不能直接窃取用户的任何信息。他们能做到的，是**欺骗用户浏览器，让其以用户的名义运行操作**。 [1] 
>
>## 防御措施
>
>**检查Referer字段**
>
>HTTP头中有一个Referer字段，这个字段用以标明请求来源于哪个地址。在处理敏感数据请求时，通常来说，Referer字段应和请求的地址位于同一域名下。以上文银行操作为例，Referer字段地址通常应该是转账按钮所在的网页地址，应该也位于www.examplebank.com之下。而如果是CSRF攻击传来的请求，Referer字段会是包含恶意网址的地址，不会位于www.examplebank.com之下，这时候服务器就能识别出恶意的访问。
>
>这种办法简单易行，工作量低，仅需要在关键访问处增加一步校验。但这种办法也有其局限性，因其完全依赖浏览器发送正确的Referer字段。虽然http协议对此字段的内容有明确的规定，但并无法保证来访的浏览器的具体实现，亦无法保证浏览器没有安全漏洞影响到此字段。并且也存在攻击者攻击某些浏览器，篡改其Referer字段的可能。
>
>**添加校验token**
>
>由于CSRF的本质在于攻击者欺骗用户去访问自己设置的地址，所以如果要求在访问敏感数据请求时，要求用户浏览器提供不保存在cookie中，并且攻击者无法伪造的数据作为校验，那么攻击者就无法再运行CSRF攻击。这种数据通常是窗体中的一个数据项。服务器将其生成并附加在窗体中，其内容是一个伪随机数。当客户端通过窗体提交请求时，这个伪随机数也一并提交上去以供校验。正常的访问时，客户端浏览器能够正确得到并传回这个伪随机数，而通过CSRF传来的欺骗性攻击中，攻击者无从事先得知这个伪随机数的值，服务端就会因为校验token的值为空或者错误，拒绝这个可疑请求。

# [cookie](https://baike.baidu.com/item/cookie/1119?fr=aladdin)

>Cookie 是一段不超过4KB的小型[文本](https://baike.baidu.com/item/文本/5443630)数据，由一个名称（Name）、一个值（Value）和其它几个用于控制Cookie有效期、安全性、使用范围的可选属性组成。其中 [3] ：
>
>(1)Name/Value：设置Cookie的名称及相对应的值，对于认证Cookie，Value值包括Web服务器所提供的访问令牌 [3] 。
>
>(2)Expires属性：设置Cookie的生存期。有两种存储类型的Cookie：会话性与持久性。Expires属性缺省时，为会话性Cookie，仅保存在[客户端](https://baike.baidu.com/item/客户端/101081)内存中，并在用户关闭浏览器时失效；持久性Cookie会保存在用户的硬盘中，直至生存期到或用户直接在网页中单击“注销”等按钮结束会话时才会失效 [3] 。
>
>(3)Path属性：定义了Web站点上可以访问该Cookie的目录 [3] 。
>
>(4)Domain属性：指定了可以访问该 Cookie 的 Web 站点或域。Cookie 机制并未遵循严格的同源策略，允许一个[子域](https://baike.baidu.com/item/子域/5873902)可以设置或获取其父域的 Cookie。当需要实现单点登录方案时，Cookie 的上述特性非常有用，然而也增加了 Cookie受攻击的危险，比如攻击者可以借此发动会话定置攻击。因而，浏览器禁止在 [Domain](https://baike.baidu.com/item/Domain/68165) 属性中设置.org、.com 等通用顶级域名、以及在国家及地区顶级域下注册的二级域名，以减小攻击发生的范围 [3] 。
>
>(5)Secure属性：指定是否使用[HTTPS](https://baike.baidu.com/item/HTTPS/285356)安全协议发送 Cookie。使用HTTPS安全协议，可以保护Cookie在浏览器和Web服务器间的传输过程中不被窃取和篡改。该方法也可用于Web站点的身份鉴别，即在HTTPS的连接建立阶段，浏览器会检查Web网站的[SSL](https://baike.baidu.com/item/SSL/320778)证书的有效性。但是基于兼容性的原因（比如有些网站使用自签署的证书）在检测到[SSL证书](https://baike.baidu.com/item/SSL证书/5201468)无效时，浏览器并不会立即终止用户的连接请求，而是显示安全风险信息，用户仍可以选择继续访问该站点。由于许多用户缺乏安全意识，因而仍可能连接到Pharming攻击所伪造的网站 [3] 。
>
>(6)HTTPOnly 属性 ：用于防止客户端脚本通过document.cookie属性访问Cookie，有助于保护Cookie不被跨站脚本攻击窃取或篡改。但是，HTTPOnly的应用仍存在局限性，一些浏览器可以阻止客户端脚本对Cookie的读操作，但允许写操作；此外大多数浏览器仍允许通过[XMLHTTP](https://baike.baidu.com/item/XMLHTTP/481421)对象读取[HTTP](https://baike.baidu.com/item/HTTP/243074)响应中的Set-Cookie头 [3] 。

# UML 专题

## 绘制流程图中的注意事项

>绘制流程图中的注意事项：
>
>1、绘制流程图时，为了提高流程图的逻辑性，应遵循从左到右、从上到下的顺序排列。
>
>2、绘制流程图时，为了提高流程图的逻辑性，应遵循从左到右、从上到下的顺序排列。一个流程从开始符开始，以结束符结束。开始符号只能出现一次，而结束符号可出现多次。若流程足够清晰，可省略开始、结束符号。
>
>3、菱形为判断符号，必须要有“是和否（或Y和N）”两种处理结果，意思是说，菱形判断框一定需要有两条箭头流出；且判断符号的上下端流入流出一般用“是（或Y）”，左右端流入流出用“否（或Y）”。
>
>4、同一流程图内，符号大小需要保持一致，同时连接线不能交叉，连接线不能无故弯曲。
>
>5、流程处理关系为并行关系的，需要将流程放在同一高度。
>
>6、必要时应采用标注，以此来清晰地说明流程，标注要用专门的标注符号。
>
>7、处理流程须以单一入口和单一出口绘制，同一路径的指示箭头应只有一个。

# 服务网格化

## [What’s a service mesh? And why do I need one?](https://buoyant.io/what-is-a-service-mesh/)

## [linkerd](https://linkerd.io/2.11/overview/)

## [下一代微服务网格化](https://www.jianshu.com/p/16998a350ca8)



# Common-cli的使用

https://www.jianshu.com/p/c3ae61787a42

### 简介

`common-cli`组件是一个解析命令参数的jar包，它能解析`gnu`风格参数、`posix`风格参数。精简而又强大，大小仅由二十多个`class`组成，maven地址如下：

```java
<dependency>
    <groupId>commons-cli</groupId>
    <artifactId>commons-cli</artifactId>
    <version>1.4</version>
</dependency>
```

# CAP

一致性（C）：在[分布式系统](https://baike.baidu.com/item/分布式系统/4905336)中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）

可用性（A）：保证每个请求不管成功或者失败都有响应。

分区容忍性（P）：系统中任意信息的丢失或失败不会影响系统的继续运作。 [1] 

## CAP 定理的含义

https://www.ruanyifeng.com/blog/2018/07/cap.html

>## 五、Consistency 和 Availability 的矛盾
>
>**一致性和可用性，为什么不可能同时成立？答案很简单，因为可能通信失败（即出现分区容错）。**
>
>如果保证 G2 的一致性，那么 G1 必须在写操作时，锁定 G2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，G2 不能读写，没有可用性不。
>
>如果保证 G2 的可用性，那么势必不能锁定 G2，所以一致性不成立。
>
>综上所述，G2 无法同时做到一致性和可用性。系统设计时只能选择一个目标。如果追求一致性，那么无法保证所有节点的可用性；如果追求所有节点的可用性，那就没法做到一致性。
>
>[更新 2018.7.17]
>
>读者问，在什么场合，可用性高于一致性？
>
>举例来说，发布一张网页到 CDN，多个服务器有这张网页的副本。后来发现一个错误，需要更新网页，这时只能每个服务器都更新一遍。
>
>一般来说，网页的更新不是特别强调一致性。短时期内，一些用户拿到老版本，另一些用户拿到新版本，问题不会特别大。当然，所有人最终都会看到新版本。所以，这个场合就是可用性高于一致性。

# 单元测试

## [单元测试 注入方法 @ExtendWith](https://www.cnblogs.com/pass-ion/p/15064785.html)

>当涉及Spring时：
>
>如果您想在测试中使用Spring测试框架功能（例如）`@MockBean`，则必须使用`@ExtendWith(SpringExtension.class)`。它取代了不推荐使用的JUnit4`@RunWith(SpringJUnit4ClassRunner.class)`
>
>当不涉及Spring时：
>
>例如，如果您只想涉及Mockito而不必涉及Spring，那么当您只想使用`@Mock`/ `@InjectMocks`批注时，您就想使用`@ExtendWith(MockitoExtension.class)`，因为它不会加载到很多不需要的Spring东西中。它替换了不推荐使用的JUnit4 `@RunWith(MockitoJUnitRunner.class)`。
>
>要回答您的问题：
>
>是的，您可以只使用`@ExtendWith(SpringExtension.class)`，但是如果您的测试中没有涉及Spring测试框架功能，那么您可能只想使用`@ExtendWith(MockitoExtension.class)`。

## [Mockito中的@Mock和@Spy如何使用 ](https://www.cnblogs.com/zendwang/p/mockito-mock-spy-usage.html)

>### 相同点
>
>spy和mock生成的对象不受spring管理
>
>### 不同点
>
>**1.默认行为不同**
>
>对于未指定mock的方法，spy默认会调用真实的方法，有返回值的返回真实的返回值，而mock默认不执行，有返回值的，默认返回null
>
>**2.使用方式不同
>
>**Spy中用when...thenReturn私有方法总是被执行，预期是私有方法不应该执行，因为很有可能私有方法就会依赖真实的环境。
>Spy中用doReturn..when才会不执行真实的方法。
>
>mock中用 when...thenReturn 私有方法不会执行*。
>
>**3.代码统计覆盖率不同
>**@spy使用的真实的对象实例，调用的都是真实的方法，所以通过这种方式进行测试，在进行sonar覆盖率统计时统计出来是有覆盖率；
>@mock出来的对象可能已经发生了变化，调用的方法都不是真实的，在进行sonar覆盖率统计时统计出来的Calculator类覆盖率为0.00%。



# jinkens

## 持续集成：Jenkins Pipeline语法介绍

https://blog.csdn.net/u010698107/article/details/122913713

# 限流算法

## 亿级流量治理系列：常用的限流算法有哪些

https://mp.weixin.qq.com/s/ZxTQ4CqbM8t6XsPEnaQFVw